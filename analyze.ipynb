{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, warnings, logging, pickle, bz2\n",
    "from os.path import join\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "sys.path.append('..')\n",
    "import trilabtracker as tt\n",
    "\n",
    "from importlib import reload\n",
    "for m in tt.__all__:\n",
    "    eval(f'reload(tt.{m})')\n",
    "reload(tt)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 6,4\n",
    "dpi = 150\n",
    "\n",
    "analysis_dir = './analysis'\n",
    "R_cm         = 55.5\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare trial data.\n",
    "\n",
    "Prepare a dictionary of trials to analyze with basic info for each (path to trial file, population, age, number of individuals, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list of trial names to use in the analysis.\n",
    "valid_trials = open('settings/adult-trials-to-analyze.txt').readlines()\n",
    "valid_trials = [ fn.strip() for fn in valid_trials ]\n",
    "\n",
    "# Extract trial metadata from the trial's filename.\n",
    "def parse_trial_file(trial_file, etho=False):\n",
    "#     if etho:\n",
    "#         trial_dir  = None\n",
    "#         trial_name = os.path.basename(trial_file)\n",
    "#         trial_name = trial_name.split('-')[1]\n",
    "#     else:\n",
    "    trial_dir  = os.path.dirname(trial_file)\n",
    "    trial_name = os.path.basename(trial_dir)\n",
    "    _,pop,n    = trial_name.lower().split('_')[:3]\n",
    "    n_ind      = int(n[1:])\n",
    "    if 'dark' in trial_name.lower():\n",
    "        pop = pop+'-dark'\n",
    "        # Skip dark trials until I implement one-sided background subtraction.\n",
    "#         return None\n",
    "    \n",
    "    if not trial_name in valid_trials:\n",
    "        return None\n",
    "    trial      = { k:v for k,v in locals().items() if k in ['trial_file', \n",
    "                              'trial_dir', 'trial_name', 'pop', 'n_ind'] }\n",
    "    trial['R_cm'] = R_cm\n",
    "    return trial\n",
    "\n",
    "# trilabtracker only for now\n",
    "def load_trial(trial_file, **args):\n",
    "    trial = parse_trial_file(trial_file)\n",
    "    return tt.preprocess_trial(trial, **args)\n",
    "\n",
    "# Select a set of trials to analyze.\n",
    "trial_files = sorted(glob('tracking_output/*/trial.pik'))\n",
    "# print(trial_files)\n",
    "\n",
    "# Count trials of each type.\n",
    "trials = [ parse_trial_file(f) for f in trial_files ]\n",
    "trials = pd.DataFrame(trials, index=trial_files)\n",
    "grouped_trials = trials.groupby(['pop','n_ind'])\n",
    "count  = pd.DataFrame(grouped_trials['trial_dir'].count().rename('count'))\n",
    "count = count.unstack(1)\n",
    "count.columns = count.columns.droplevel()\n",
    "count[pd.isna(count)] = 0\n",
    "count = count.astype(int)\n",
    "display(count)\n",
    "\n",
    "# def matching_trials(pop=None, age=None, n_ind=None, df=trials):\n",
    "#     I = pd.Series(data=True, index=df.index)\n",
    "#     if not pop is None:\n",
    "#         I = I & (df['pop']==pop)\n",
    "#     if not age is None:\n",
    "#         I = I & (df['age']==age)\n",
    "#     if not n_ind is None:\n",
    "#         I = I & (df['n_ind']==n_ind)\n",
    "#     return df[I].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute or load analyzed data.\n",
    "\n",
    "The first subsection iterates over the list of trials, loads the full tracking output, compute kinematic quantities, performs cuts, computes statistical properties (distribution of speed, angular speed, pairwise distance-angle, etc), and saves them.\n",
    "\n",
    "The second subsection loads precomputed statistical properties made with the first cell.\n",
    "\n",
    "### Define cuts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_ranges    = { 'v':[0,100], 'v_ang':[-30,30], 't':[600,1800] }\n",
    "# This is used to name the output directory and make figure titles.\n",
    "# The \"=\" should be \"<=\" however ntfs doesn't allow \"<\" in filenames.\n",
    "cut_label     = ', '.join([ f'{v[0]:g}={k}={v[1]:g}' for k,v in cut_ranges.items() ])\n",
    "\n",
    "cut_dir = os.path.join(analysis_dir, cut_label)\n",
    "if not os.path.exists(cut_dir):\n",
    "    os.mkdir(cut_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "for m in tt.__all__:\n",
    "    eval(f'reload(tt.{m})')\n",
    "reload(tt)\n",
    "\n",
    "traj_data = {}\n",
    "stat_data = dict(\n",
    "    bins_dWall    = np.linspace(0,R_cm,100), \n",
    "    bins_v        = np.linspace(*cut_ranges['v'],100), \n",
    "    bins_vAng     = np.linspace(*cut_ranges['v_ang'],100), \n",
    "    bins_pairDist = np.linspace(0,2*R_cm,60), \n",
    "    bins_pairAng  = np.linspace(0,np.pi,30), \n",
    "    )\n",
    "globals().update(stat_data)\n",
    "results = {}\n",
    "\n",
    "for trial_file in tqdm(trials.index):\n",
    "    \n",
    "    trial = load_trial(trial_file, load_timestamps=False, cut_ranges=cut_ranges)\n",
    "    globals().update(trial)\n",
    "    \n",
    "    # [?] Replace orientations (data[:,:,2]) with displacement-based ones.\n",
    "    \n",
    "    # Save trajectories.\n",
    "    traj_data[trial_name] = pos[:,:,:2]\n",
    "    \n",
    "    # [!] Handle overlaps.\n",
    "    \n",
    "    # Distribution of distance to the wall.\n",
    "    bins, vals = bins_dWall, d_wall.flatten()\n",
    "    hist_dWall = np.histogram(vals[~np.isnan(vals)], bins=bins)\n",
    "    \n",
    "    # Speed distribution.\n",
    "    bins, vals = bins_v, v.flatten()\n",
    "    hist_v = np.histogram(vals[~np.isnan(vals)], bins=bins)\n",
    "    \n",
    "    # Angular speed distribution.\n",
    "    bins, vals = bins_vAng, vel[:,:,2].flatten()\n",
    "    hist_vAng = np.histogram(vals[~np.isnan(vals)], bins=bins)\n",
    "    \n",
    "    # Joint distribution of pair distance and pair angle,\n",
    "    if n_ind>1:\n",
    "        bins_d  = bins_pairDist\n",
    "        bins_a  = bins_pairAng\n",
    "        J1,J2 = np.triu_indices(n_ind,1)\n",
    "        d     = np.hypot(pos[:,J1,0]-pos[:,J2,0],pos[:,J1,1]-pos[:,J2,1]).flatten()\n",
    "        a     = (pos[:,J1,2]-pos[:,J2,2]).flatten()\n",
    "        a     = a - 2*np.pi*np.rint(a/(2*np.pi))\n",
    "        I     = np.logical_not(np.logical_or(np.isnan(d),np.isnan(a)))\n",
    "        d     = d[I]\n",
    "        a     = np.absolute(a[I])\n",
    "        # 2D histogram of pairwise distance and angle.\n",
    "        hist_distAng = np.histogram2d(d, a, bins=(bins_d,bins_a), density=True)\n",
    "        # Pairwise polar alignment parameter vs pair distance.\n",
    "        K = np.digitize(d,bins_d)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            p = np.array([ np.nanmean(np.cos(a[K==i])) for i in range(len(bins_d)+1) ])\n",
    "        polar = p[1:-1],bins_d\n",
    "    else:\n",
    "        hist_distAng,polar = None,None\n",
    "\n",
    "    # Save output.\n",
    "    results[trial_file] = { k:v for k,v in locals().items() if k in \n",
    "                               [ 'valid_fraction', 'hist_area', 'hist_aspect', 'hist_dWall', \n",
    "                                 'hist_v', 'hist_vAng', 'hist_distAng', 'polar' ] }\n",
    "#     break\n",
    "\n",
    "stat_data['results'] = results\n",
    "pickle.dump(stat_data, open(join(cut_dir,'stats.pik'), 'wb'))\n",
    "pickle.dump(traj_data, open(join(cut_dir,'trajectories.pik'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_data = pickle.load(open(join(cut_dir,'trajectories.pik'), 'rb'))\n",
    "\n",
    "for trial_name,pos in list(traj_data.items())[:1]:\n",
    "    plt.figure(figsize=(6,)*2)\n",
    "    plt.axis('off')\n",
    "    labels = [f'fish {i+1}' for i in range(pos.shape[1])]\n",
    "    plt.plot(pos[:,:,0], pos[:,:,1], lw=0.2, label=labels)\n",
    "    plt.title(trial_name)\n",
    "    plt.legend(loc=(1,0.1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load precomputed analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List previously computed cuts.\n",
    "cut_dirs  = os.listdir(analysis_dir)\n",
    "print(cut_dirs)\n",
    "\n",
    "# Pick one and load data.\n",
    "cut_label = cut_dirs[0]\n",
    "cut_dir   = os.path.join(analysis_dir, cut_label)\n",
    "stat_data = pickle.load(open(join(cut_dir,'stats.pik'), 'rb'))\n",
    "globals().update(stat_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot individual trial data\n",
    "\n",
    "Distributions and other statistical quantities were precomputed in the previous section. Time series and trajectories plots require to reload each trial's trial file, one at a time.\n",
    "\n",
    "### Trajectories and time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_dir = { k:os.path.join(analysis_dir,cut_label,k) for k in \n",
    "#                ['trajectories', 'angle-vs-time'] }\n",
    "# for d in fig_dir.values():\n",
    "#     if not os.path.exists(d):\n",
    "#         os.mkdir(d)\n",
    "\n",
    "# # Creating a new figure for each trial creates a memory leak\n",
    "# # I haven't been able to plug, so I'm creating one figure for\n",
    "# # trajectories and one for angles and reusing them.\n",
    "# fig_traj = plt.figure(figsize=(9,)*2)\n",
    "# fig_ang  = plt.figure(figsize=(12,6))\n",
    "\n",
    "# for i,trial_file in enumerate(trials.index):\n",
    "#     print('\\r'+' '*200+'\\r'+f'{i+1}/{len(trials)}',end='')\n",
    "    \n",
    "#     trial = load_trial(trial_file, load_data=True)\n",
    "#     trial = compute_kinematics(trial)\n",
    "#     globals().update(trial)\n",
    "    \n",
    "#     # Trajectories.\n",
    "#     fig,ax = fig_traj,fig_traj.gca()\n",
    "#     ax.add_patch(plt.Circle(center, R_px, facecolor='None', \n",
    "#                                    edgecolor='k', lw=0.5))\n",
    "#     ax.plot(*np.moveaxis(data[::5,:n_ind,:2],2,0),lw=0.5)\n",
    "#     ax.axis('equal')\n",
    "#     ax.yaxis.set_inverted(True)\n",
    "#     fig.suptitle(trial_name)\n",
    "#     fig.savefig(os.path.join(fig_dir['trajectories'],trial_name+'.png'))\n",
    "#     fig.clf()\n",
    "    \n",
    "#     # Angle vs time.\n",
    "#     fig,ax = fig_traj,fig_traj.gca()\n",
    "#     ax.plot(time[:,None],pos[:,:,2])\n",
    "#     ax.set_xlabel('Time (s)')\n",
    "#     ax.set_ylabel('Angle (rad)')\n",
    "#     fig.suptitle(trial_name)\n",
    "#     fig.savefig(os.path.join(fig_dir['angle-vs-time'],trial_name+'.png'))\n",
    "#     fig.clf()\n",
    "    \n",
    "# plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = { k:join(cut_dir,k) for k in [ 'valid_fraction', \n",
    "            'hist_dWall', 'hist_v', 'hist_vAng', 'hist_distAng', 'polar' ] }\n",
    "for d in fig_dir.values():\n",
    "    if not os.path.exists(d):\n",
    "        os.mkdir(d)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "# ax  = fig.gca()\n",
    "\n",
    "for trial_file in tqdm(trials.index):\n",
    "    \n",
    "    globals().update(trials.loc[trial_file].to_dict())\n",
    "    globals().update(trial_data[trial_file])\n",
    "    \n",
    "    # Valid fraction.\n",
    "    bp = plt.bar(*zip(*valid_fraction.items()))\n",
    "    for bar in bp:\n",
    "        h,x,w = bar.get_height(),bar.get_x(),bar.get_width()\n",
    "        plt.annotate(f'{h:.2f}', xy=(x+w/2,1.01), ha='center', va='bottom')\n",
    "    plt.ylim(0,1.1)\n",
    "    plt.ylabel('Valid fraction')\n",
    "    plt.title(cut_label)\n",
    "    plt.suptitle(trial_name)\n",
    "    plt.savefig(os.path.join(fig_dir['valid_fraction'],trial_name+'.png'))\n",
    "    plt.close()\n",
    "    \n",
    "#     # Distributions of distance to the wall, speed, and angular speed.\n",
    "#     H = dict( hist_dWall='d_wall (cm)', hist_v='v (cm/s)', hist_vAng='v_ang (rad/s)' )\n",
    "#     for name,label in H.items():\n",
    "#         ax = fig.gca()\n",
    "#         h,b = locals()[name]\n",
    "#         ax.bar(b[:-1],h,width=b[1:]-b[:-1])\n",
    "#         ax.set_yscale('log')\n",
    "#         ax.set_xlabel(label)\n",
    "#         ax.set_ylabel('frequency')\n",
    "#         ax.set_title(cut_label)\n",
    "#         fig.suptitle(trial_name)\n",
    "#         fig.savefig(os.path.join(fig_dir[name],trial_name+'.png'))\n",
    "#         fig.clf()\n",
    "    \n",
    "#     # Pairwise distance-angle distribution.\n",
    "#     if not hist_distAng is None:\n",
    "#         ax = fig.gca()\n",
    "#         h,b1,b2 = hist_distAng\n",
    "#         m = ax.pcolormesh(b1, b2*180/np.pi, h.T, cmap='Oranges')\n",
    "#         ax.set_xlabel('pair distance (cm)')\n",
    "#         ax.set_ylabel('pair angle (deg)')\n",
    "#         fig.colorbar(m)\n",
    "#         ax.set_title(cut_label)\n",
    "#         fig.suptitle(trial_name)\n",
    "#         fig.savefig(os.path.join(fig_dir['hist_distAng'],trial_name+'.png'))\n",
    "#         fig.clf()\n",
    "    \n",
    "#     # Pairwise polar order parameter vs distance.\n",
    "#     if not polar is None:\n",
    "#         ax = fig.gca()\n",
    "#         p,b = polar\n",
    "#         ax.plot((b[1:]+b[:-1])/2,p,marker='o',mfc='None',ms=4)\n",
    "#         ax.set_xlabel('pair distance (cm)')\n",
    "#         ax.set_ylabel('mean cosine of pair angle')\n",
    "#         ax.set_ylim(-1,1)\n",
    "#         ax.set_title(cut_label)\n",
    "#         fig.suptitle(trial_name)\n",
    "#         fig.savefig(os.path.join(fig_dir['polar'],trial_name+'.png'))\n",
    "#         fig.clf()\n",
    "    \n",
    "#     break\n",
    "\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' Analyze instances of unusually high velocity. '''\n",
    "\n",
    "# # At 30 fps, |v_ang|=30 (about where the rare peaks start) \n",
    "# # corresponds to about pi/3 in one frame.\n",
    "# print('v_ang for pi/3 in (1/30) second:',np.pi/3*fps)\n",
    "\n",
    "# print('Instances of unusually high v_ang:')\n",
    "# for f in fish_list:\n",
    "#     ang_diff  = df[f,'ang'].diff()\n",
    "#     I = np.nonzero(np.absolute(ang_diff.values)>1)[0]\n",
    "#     for i in I[:5]:\n",
    "#         display(df[f,'ang'].iloc[i-1:i+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (main)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
