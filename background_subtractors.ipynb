{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import platform, os, sys, datetime, re\n",
    "from os.path import join\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tracker.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_settings = dict(\n",
    "#     # Background subtraction.\n",
    "#     bkgSub_options   = dict( n_training_frames = 200,   # number of frames used to compute background\n",
    "#                              t_start = 0, t_end = 1200, # time range used to compute background\n",
    "#                              contrast_factor = 5,       # post-subtraction contrast enhancement factor\n",
    "#                              secondary_subtraction = True, \n",
    "#                              secondary_factor = 2       # frame = frame-secondary_factor*secondary_background\n",
    "#                            ),\n",
    "#     t_start          = 0,     # Time at which to start tracking, in seconds.\n",
    "#     t_end            = 1200,  # Time at which to end tracking, in seconds.\n",
    "    \n",
    "#     # Contour detection.\n",
    "#     n_blur           =  7,    # square-root of n-pixels for threshold blurring\n",
    "#     block_size       = 15,    # contour block size\n",
    "#     threshold_offset = 13,    # threshold offset for contour-finding\n",
    "#     min_area         = 25,    # minimum area for detection\n",
    "#     max_area         = 600,   # maximum area for detection\n",
    "#     ideal_area       = 100,   # ideal area to rank contours in first frame (default=(min_area+max_area)/2)\n",
    "#     max_aspect       = 15,    # maximum aspect ratio for detection\n",
    "#     ideal_aspect     = 3,     # ideal aspect ratio to rank contours in first frame (default=max_aspect/2)\n",
    "#     area_penalty     = 0.5,   # weight of area change when connecting fish across frames\n",
    "#     n_extra          = 2,     # number of extra contours to keep track of\n",
    "#     morph_transform  = [], \n",
    "# #     morph_transform  = [(cv2.MORPH_OPEN,2),(cv2.MORPH_CLOSE,2)], \n",
    "# #     morph_transform  = [(cv2.MORPH_CLOSE,20),(cv2.MORPH_OPEN,3)], \n",
    "# #     morph_transform  = [(cv2.MORPH_DILATE,5),(cv2.MORPH_OPEN,8)], \n",
    "#                               # sequence of morphological operations to perform\n",
    "#                               # on thresholded image before extracting contours.\n",
    "#     reversal_threshold = 0.5, # average frame-to-frame displacement against the director \n",
    "#                               # over the last few frames to trigger a reversal. \n",
    "    \n",
    "#     # Visualization.\n",
    "#     save_video       = False, \n",
    "#     # What information to draw on the tracking output video.\n",
    "#     video_output_options = dict( tank=True, points=False, directors=True, \n",
    "#                                  extra_points=True, timestamp=True, \n",
    "#                                  contours=True, contour_color=(100,255,0), \n",
    "#                                  contour_thickness=1 )\n",
    "#     )\n",
    "\n",
    "# video_file = '../raw_videos/Pa_Fri_7dpf_GroupD_n2_20200605_1400.avi'\n",
    "# output_dir = './output/bkgSub'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the background\n",
    "\n",
    "### Using a naive average\n",
    "\n",
    "Compute the background by averaging frames over the entire video. Save it as `background.npy` in the output directory. Use the pre-existing file if there is one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2.bgsegm import *\n",
    "\n",
    "# def subtract_background(frame, bkg, bkg_contrast_factor):\n",
    "#     return 255-np.minimum(255,bkg_contrast_factor*np.absolute(frame-bkg)).astype(np.uint8)    \n",
    "\n",
    "bg_opt = dict( n_training_frames = 200,   # number of frames used to compute background\n",
    "               t_start = 0, t_end = 1200, # time range used to compute background\n",
    "               contrast_factor = 5,       # post-subtraction contrast enhancement factor\n",
    "               secondary_subtraction = True, \n",
    "               secondary_factor = 2       # frame = frame-secondary_factor*secondary_background\n",
    "             )\n",
    "\n",
    "class NaiveBackground():\n",
    "    \n",
    "    def __init__(self, opt=bg_opt):\n",
    "        self.name = 'naive'\n",
    "        self.__dict__.update(bg_opt)\n",
    "        self.count = 0\n",
    "    \n",
    "    def add_training_image(self, img):\n",
    "        if not hasattr(self,'bg'):\n",
    "            self.bg  = np.zeros(img.shape,dtype=np.float32)\n",
    "            self.f32 = np.empty_like(self.bg)\n",
    "        self.bg    += img\n",
    "        self.count += 1\n",
    "        \n",
    "    def wrapup_training(self):\n",
    "        self.bg /= self.count\n",
    "        \n",
    "    def apply_background(self, img):\n",
    "#         return img-self.bg\n",
    "        np.subtract(img, self.bg, out=self.f32)\n",
    "        np.multiply(self.f32, self.contrast_factor, out=self.f32)\n",
    "        np.absolute(self.f32, out=self.f32)\n",
    "        np.minimum(self.f32, 255, out=self.f32)\n",
    "        img[...] = self.f32\n",
    "        return img\n",
    "    \n",
    "class CvBackground():\n",
    "    \n",
    "    def __init__(self,bg_type,n_frames):\n",
    "        self.name = bg_type\n",
    "        if bg_type in ['MOG2','KNN','MOG']:\n",
    "            bg_sub = globals()['createBackgroundSubtractor'+bg_type](history=n_frames)\n",
    "        elif bg_type in ['CNT','GMG','GSOC','LSBP']:\n",
    "            bg_sub = globals()['createBackgroundSubtractor'+bg_type]()\n",
    "        else:\n",
    "            raise Exception('Unkown background subtractor.')\n",
    "    \n",
    "    def add_training_image(self, img):\n",
    "        pass\n",
    "    \n",
    "    def wrapup_training(self):\n",
    "        # Tell subtractor to stop learning.\n",
    "        pass\n",
    "        \n",
    "    def apply_background(self, img):\n",
    "        return self.bg.apply(img)\n",
    "\n",
    "def compute_background(video_file,bg):\n",
    "    cap         = cv2.VideoCapture(video_file)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_skip  = frame_count//bg.n_training_frames\n",
    "    for n in range(0,frame_count,frame_skip):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES,n)\n",
    "        ret,frame = cap.read()\n",
    "        bg.add_training_image(frame)\n",
    "    bg.wrapup_training()\n",
    "    cap.release()\n",
    "    return\n",
    "\n",
    "def make_subtracted_video(video_file,bg):\n",
    "    cap         = cv2.VideoCapture(video_file)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps         = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width       = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height      = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    output_file = join(output_dir,bg.name+'.mp4')\n",
    "    fourcc      = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out         = cv2.VideoWriter( filename = output_file, frameSize = (width,height), \n",
    "                                   fourcc = fourcc, fps = fps, isColor = True )\n",
    "    skip        = frame_count//4\n",
    "    for n in range(0,frame_count-skip,skip):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES,n)\n",
    "        for i in range(2*fps):\n",
    "            ret,frame = cap.read()\n",
    "            bg.apply_background(frame)\n",
    "            out.write(255-frame)\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:01.917877\n",
      "0:00:15.108209\n"
     ]
    }
   ],
   "source": [
    "video_file = '../raw_videos/Pa_Fri_7dpf_GroupD_n2_20200605_1400.avi'\n",
    "output_dir = './output/bkgSub'\n",
    "\n",
    "bg_opt = dict( n_training_frames = 10,    # number of frames used to compute background\n",
    "               t_start = 0, t_end = 1200, # time range used to compute background\n",
    "               contrast_factor = 5,       # post-subtraction contrast enhancement factor\n",
    "               secondary_subtraction = True, \n",
    "               secondary_factor = 2       # frame = frame-secondary_factor*secondary_background\n",
    "             )\n",
    "\n",
    "t0          = datetime.datetime.now()\n",
    "bg          = NaiveBackground(bg_opt)\n",
    "compute_background(video_file,bg)\n",
    "t1          = datetime.datetime.now()\n",
    "print(t1-t0)\n",
    "make_subtracted_video(video_file,bg)\n",
    "t2          = datetime.datetime.now()\n",
    "print(t2-t1)\n",
    "sys.stdout.flush()\n",
    "\n",
    "# np.savez_compressed(join(output_dir,'naive.npz'),bg=bg.bg)\n",
    "# cv2.imwrite(join(output_dir,'naive.png'),bg.bg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using various methods from openCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals().update(settings)\n",
    "\n",
    "from cv2 import createBackgroundSubtractorKNN, createBackgroundSubtractorMOG2\n",
    "from cv2.bgsegm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bg in bg_types:\n",
    "#     help(createBackgroundSubtractorCNT)\n",
    "    help(globals()['createBackgroundSubtractor'+bg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOG2\n",
      "KNN\n",
      "CNT\n",
      "GMG\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:715: error: (-215:Assertion failed) !_img.empty() in function 'imwrite'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.2.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:715: error: (-215:Assertion failed) !_img.empty() in function 'imwrite'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSOC\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSBP\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOG\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Ntraining = 50\n",
    "\n",
    "bg_types = ['MOG2','KNN','CNT','GMG','GSOC','LSBP','MOG']\n",
    "# bg_types = ['MOG2','GSOC','CNT']\n",
    "\n",
    "# bg_sub = cv2.createBackgroundSubtractorMOG2(history=Ntraining) #, varThreshold=25, detectShadows=False)\n",
    "# bg_sub = createBackgroundSubtractorKNN() #history=10*Ntraining)\n",
    "# bg_sub = createBackgroundSubtractorCNT()\n",
    "# bg_sub = createBackgroundSubtractorGMG()\n",
    "# bg_sub = createBackgroundSubtractorGSOC()\n",
    "# bg_sub = createBackgroundSubtractorLSBP()\n",
    "# bg_sub = createBackgroundSubtractorMOG()\n",
    "\n",
    "bgs_dir = join(output_dir,'backgrounds')\n",
    "if not os.path.exists(bgs_dir):\n",
    "    os.mkdir(bgs_dir)\n",
    "\n",
    "for bg in bg_types:\n",
    "    \n",
    "    print(bg)\n",
    "\n",
    "    cap = cv2.VideoCapture(new_input_file)\n",
    "    Nframes = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    training_frames = np.linspace(0, Nframes-1, Ntraining, dtype=int)\n",
    "    \n",
    "    try:\n",
    "        opt = dict(history=Ntraining) if bg in ['MOG2','KNN','MOG'] else {}\n",
    "        bg_sub = globals()['createBackgroundSubtractor'+bg](**opt)\n",
    "\n",
    "        for i in training_frames:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "            ret,frame = cap.read()\n",
    "    #         print(ret)\n",
    "            if ret:\n",
    "                bg_sub.apply(frame,learningRate=1/Ntraining)\n",
    "        #         cv2.imwrite(f'test/MOG/{i}.png',bg_sub.getBackgroundImage())\n",
    "\n",
    "        cap.release()\n",
    "#         cv2.imwrite(f'test/MOG/{bg}-{Ntraining}.png',bg_sub.getBackgroundImage())\n",
    "        cv2.imwrite(join(bgs_dir,f'{bg}-{Ntraining}.png'),bg_sub.getBackgroundImage())\n",
    "    except:\n",
    "        cap.release()\n",
    "        %tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (main)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
