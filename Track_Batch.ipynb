{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform, os, sys, datetime, re\n",
    "import multiprocessing\n",
    "from os.path import join\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# sys.path.append(join(root_dir,'cvtracer'))\n",
    "from cvt.TrAQ.Trial import Trial\n",
    "from cvt.TrAQ.Tank import Tank\n",
    "from cvt.TrAQ.Group import Group\n",
    "from cvt.TrAQ.CVTracer import CVTracer, create_named_window, wait_on_named_window\n",
    "from cvt.utils import *\n",
    "\n",
    "\n",
    "settings_list = [ # trial settings\n",
    "                  'input_file', 'tracking_dir', 'output_dir', \n",
    "                  'new_input_file', 'bkg_file', 'tank_file', 'settings_file', \n",
    "                  't_start', 't_end', 'tank_radius', \n",
    "                  'bkg_frame_skip', 'bkg_sub_amp',\n",
    "                  'n_pixel_blur', 'block_size', 'thresh_offset',\n",
    "                  'min_area', 'max_area', 'RGB', \n",
    "                  # tracking settings\n",
    "                  'ext', 'filename', 'pop', 'age', 'group', 'Nfish', \n",
    "                  'date', 'Nframes', 'fps', 'fourcc', 'width', 'height',\n",
    "                  'video_output_options', 'online_viewer'\n",
    "                 ]\n",
    "\n",
    "\n",
    "tank_diameter_vs_age = { 7:0.96, 14:1.04, 21:1.28, 28:1.77, 42:3.38 }\n",
    "\n",
    "\n",
    "def create_settings_(input_file,tracking_dir, \n",
    "                     settings_list=settings_list, \n",
    "                     tank_diameter_vs_age=tank_diameter_vs_age):\n",
    "\n",
    "    ''' Extract trial info from the filename and the video itself. '''\n",
    "\n",
    "    filename,ext = os.path.splitext(os.path.basename(input_file))\n",
    "    pop,_,age,group,Nfish,date = filename.split('_')\n",
    "    \n",
    "    \n",
    "    pop,_,age,group,Nfish,date = filename.split('_')\n",
    "    Nfish    = int(re.findall('\\d+',Nfish)[0])\n",
    "    date     = ''.join(date.split('-')[:3])\n",
    "    \n",
    "    tank_radius = tank_diameter_vs_age[int(age[:-3])]/2\n",
    "\n",
    "    cap      = cv2.VideoCapture(input_file)\n",
    "    cap.read()\n",
    "    Nframes  = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps      = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    fourcc   = int(cap.get(cv2.CAP_PROP_FOURCC))\n",
    "    width    = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height   = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    cap.release()\n",
    "\n",
    "    ''' Set default tracking parameters. '''\n",
    "\n",
    "    # By default only track 10 seconds 1 minute in.\n",
    "    t_start,t_end  = 0,-1  # Times between which to track, in seconds.\n",
    "\n",
    "    # Background subtraction (for naive background subtraction only).\n",
    "    bkg_frame_skip = 100   # Using every frame of the video to compute the background takes a while.\n",
    "                           # Instead we only use one frame in bkg_frame_skip.\n",
    "    bkg_sub_amp    = 4     # Contrast amplification factor applied after background subtraction.\n",
    "\n",
    "    # Contour detection.\n",
    "    n_pixel_blur   =  7    # square-root of n-pixels for threshold blurring\n",
    "    block_size     = 15    # contour block size\n",
    "    thresh_offset  = 15    # threshold offset for contour-finding\n",
    "    min_area       = 25    # minimum area for threhold detection\n",
    "    max_area       = 60    # maximum area for threhold detection\n",
    "    RGB            = False # track in color, false does greyscale\n",
    "    online_viewer  = False # Toggle live preview of tracking.\n",
    "\n",
    "    # Decide what information to draw on the tracking output video.\n",
    "    video_output_options = dict(tank=True, repeat_contours=False, all_contours=True, \n",
    "                                contour_color=(0,200,255), contour_thickness=1, \n",
    "                                points=False, directors=True, timestamp=True)\n",
    "    \n",
    "    ''' Define and create necessary folders/files/links. '''\n",
    "    \n",
    "    if not os.path.exists(tracking_dir):\n",
    "        os.mkdir(tracking_dir)\n",
    "\n",
    "    output_dir = join(tracking_dir,filename)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    new_input_file = input_file\n",
    "    if not 'windows' in platform.system().lower():\n",
    "        new_input_file = join(output_dir,'raw'+ext)\n",
    "        if not os.path.exists(new_input_file):\n",
    "            os.symlink(os.path.relpath(input_file,output_dir),new_input_file)\n",
    "\n",
    "    settings_file = join(output_dir,'tracking_settings.txt')\n",
    "    tank_file = join(output_dir,'tank.pik')\n",
    "    bkg_file  = join(output_dir,f'background-{bkg_frame_skip}.npy')\n",
    "    \n",
    "    \n",
    "    # The list comprehension version fails to find 'new_input_file'.\n",
    "    # The explicit loop version works. I have no idea why.\n",
    "#     settings  = { k:locals()[k] for k in settings_list }\n",
    "    settings = {}\n",
    "    for k in settings_list:\n",
    "        settings[k] = locals()[k]\n",
    "    \n",
    "    return settings\n",
    "\n",
    "\n",
    "''' Prepare a one-step settings saving function to run right before tracking. '''\n",
    "\n",
    "def save_settings():\n",
    "    with open(settings_file,'w') as fh:\n",
    "        for k in settings_list:\n",
    "            print(f'{k} = {globals()[k]}',file=fh)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locate input/output and allocate CPU's\n",
    "\n",
    "`tracking_dir` sets the top-level output directory. The output of tracking each video will go in `tracking_dir`, in a subdirectory named after the input video file.  \n",
    "\n",
    "`n_threads` controls the number of tracking tasks to execute simulataneously. `n_threads = None` defaults to the number of CPU's on the machine running the notebook.\n",
    "\n",
    "`input_files` set the list of video files to perform tracking on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../raw_videos/Pa_Fri_14dpf_GroupA_n2_15FPS.avi',\n",
       " '../raw_videos/Pa_Fri_14dpf_GroupA_n2b_15FPS.avi']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tracking_dir = '../tracking/full'\n",
    "\n",
    "n_threads = None\n",
    "\n",
    "input_files = sorted(glob('../raw_videos/*.avi'))\n",
    "# input_files = sorted(glob('../raw_videos/*_*_7dpf_*.avi'))\n",
    "display(input_files)\n",
    "\n",
    "#-----\n",
    "\n",
    "create_settings = lambda input_file: create_settings_(input_file,tracking_dir=tracking_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locate the tanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../raw_videos/Pa_Fri_14dpf_GroupA_n2_15FPS.avi\n",
      "\n",
      "        Tank object loaded from ../tracking/partial/Pa_Fri_14dpf_GroupA_n2_15FPS/tank.pik \n",
      "../raw_videos/Pa_Fri_14dpf_GroupA_n2b_15FPS.avi\n",
      "\n",
      "        Tank object loaded from ../tracking/partial/Pa_Fri_14dpf_GroupA_n2b_15FPS/tank.pik \n"
     ]
    }
   ],
   "source": [
    "for input_file in input_files:\n",
    "    print(input_file)\n",
    "    settings = create_settings(input_file)\n",
    "    globals().update(settings)\n",
    "    tank = Tank(r_cm=tank_radius)\n",
    "    tank.load_or_locate_and_save(tank_file,input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute backgrounds\n",
    "\n",
    "Compute the background by averaging frames over the entire video. Save it as `background.npy` in the output directory. Use the pre-existing file if there is one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_background(frame,bkg,bkg_sub_amp):\n",
    "    return 255-np.minimum(255,bkg_sub_amp*np.absolute(frame-bkg)).astype(np.uint8)    \n",
    "\n",
    "\n",
    "def compute_background(settings):\n",
    "    \n",
    "    globals().update(settings)\n",
    "    \n",
    "    if os.path.exists(bkg_file):\n",
    "        bkg  = np.load(bkg_file)\n",
    "    else:\n",
    "        t0    = datetime.datetime.now()\n",
    "        cap   = cv2.VideoCapture(new_input_file)\n",
    "        _,frame = cap.read()\n",
    "        bkg   = np.zeros(frame.shape,dtype=float)\n",
    "        count = 0\n",
    "        # If bkg_frame_skip is small (<10) it may be faster to use\n",
    "        # cap.grab instead of cap.set.\n",
    "        for n in range(0,Nframes,bkg_frame_skip):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES,n)\n",
    "            ret,frame = cap.read()\n",
    "            bkg      += frame\n",
    "            count    += 1\n",
    "        bkg   = bkg / count\n",
    "        np.save(bkg_file,bkg)\n",
    "        print(input_file)\n",
    "        print('Using every {bkg_frame_skip}th frame.')\n",
    "        print(datetime.datetime.now()-t0)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    # Show the background.\n",
    "    plt.figure(figsize=(9,9))\n",
    "    plt.imshow(bkg.astype(np.uint))\n",
    "    plt.savefig(join(output_dir,'background.png'),dpi=150)\n",
    "#     plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Single thread version.\n",
    "# for f in input_files:\n",
    "#     settings = create_settings(f)\n",
    "#     compute_background(settings)\n",
    "\n",
    "# Multithread version.\n",
    "with multiprocessing.Pool(n_threads) as pool:\n",
    "    pool.map(compute_background,[create_settings(f) for f in input_files])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track with simple background subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track(settings):\n",
    "    \n",
    "    globals().update(settings)\n",
    "    save_settings()\n",
    "    \n",
    "    trial = Trial()\n",
    "    trial.init(video_file=new_input_file, output_dir=output_dir, n=Nfish, t=pop, date=date, \n",
    "               fps=fps, tank_radius=tank_radius, t_start=t_start, t_end=t_end)\n",
    "\n",
    "    cvt = CVTracer(trial, n_pixel_blur=n_pixel_blur, block_size=block_size, \n",
    "                   threshold_offset=thresh_offset, min_area=min_area, RGB=True,\n",
    "                   online=online_viewer)\n",
    "    \n",
    "    bkg = np.load(bkg_file)\n",
    "    \n",
    "    try:\n",
    "        cvt.set_frame(cvt.frame_start)\n",
    "        for i_frame in range(cvt.frame_start, cvt.frame_end+1):\n",
    "            if cvt.get_frame():\n",
    "                cvt.frame = subtract_background(cvt.frame,bkg,bkg_sub_amp)\n",
    "                cvt.mask_tank()\n",
    "                cvt.detect_contours()\n",
    "                cvt.analyze_contours()\n",
    "                cvt.connect_frames()\n",
    "                cvt.update_trial()\n",
    "                cvt.draw(**video_output_options)\n",
    "                cvt.write_frame()\n",
    "                if not cvt.post_frame(delay=1):\n",
    "                    break\n",
    "                cvt.print_current_frame()\n",
    "        cvt.release()\n",
    "        cvt.trial.save()\n",
    "    except:\n",
    "        %tb\n",
    "        cvt.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../raw_videos/Pa_Fri_14dpf_GroupA_n2_15FPS.avi',\n",
       " '../raw_videos/Pa_Fri_14dpf_GroupA_n2b_15FPS.avi']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(input_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../raw_videos/Pa_Fri_14dpf_GroupA_n2b_15FPS.avi\n",
      "../raw_videos/Pa_Fri_14dpf_GroupA_n2_15FPS.avi\n",
      "\n",
      "        Generating new Trial object.\n",
      "\n",
      "        Tank object loaded from ../tracking/partial/Pa_Fri_14dpf_GroupA_n2b_15FPS/tank.pik \n",
      "2 individuals in trial\n",
      "\n",
      "        Generating new Trial object.\n",
      "\n",
      "        Tank object loaded from ../tracking/partial/Pa_Fri_14dpf_GroupA_n2_15FPS/tank.pik \n",
      "2 individuals in trial\n",
      "15\n",
      "Using Gaussian Adaptive Threshold\n",
      "Using Inverted Binary Threshold with [0, 100].\n",
      " Group of 2\n",
      "15\n",
      "Using Gaussian Adaptive Threshold\n",
      "Using Inverted Binary Threshold with [0, 100].\n",
      " Group of 2\n",
      "       Current tracking time: 00:00:10:10 \n",
      "       Video capture released.\n",
      "\n",
      "        Trial object saved as ../tracking/partial/Pa_Fri_14dpf_GroupA_n2b_15FPS/trial.pik \n",
      "       Current tracking time: 00:00:10:03 \n",
      "       Video capture released.\n",
      "\n",
      "        Trial object saved as ../tracking/partial/Pa_Fri_14dpf_GroupA_n2_15FPS/trial.pik \n"
     ]
    }
   ],
   "source": [
    "# # Single thread version.\n",
    "# for f in input_files:\n",
    "#     print(input_file)\n",
    "#     settings = create_settings(f)\n",
    "#     track(settings)\n",
    "\n",
    "# Multi thread version.\n",
    "def task(input_file):\n",
    "    print(input_file)\n",
    "    sys.stdout.flush()\n",
    "    settings = create_settings(input_file)\n",
    "    track(settings)\n",
    "\n",
    "with multiprocessing.Pool(n_threads) as pool:\n",
    "    pool.map(task,input_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cvtracer)",
   "language": "python",
   "name": "cvtracer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
