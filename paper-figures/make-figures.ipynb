{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEPq_SBlo3Id"
   },
   "source": [
    "The purpose of this notebook is to generate the figures for the *Astyanax Mexicanus* social behavior paper using a pre-processed dataset.\n",
    "\n",
    "Upstream of this notebook, we have tracked, processed, and analyzed data from the complete raw dataset. Here, we share data relevant to figures in a pickle file, `figure-data.pik`. Here, we show how to access and work with that file.\n",
    "\n",
    "# Imports and module versions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Print version numbers for the modules used in this notebook.\n",
    "print(f'python {sys.version}')\n",
    "for m in 'numpy', 'scipy', 'statsmodels', 'matplotlib', 'pandas', 'seaborn', 'pingouin':\n",
    "    i = __import__(m)\n",
    "    print(f'{m} {i.__version__}')\n",
    "\n",
    "# Full imports.\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.interpolate\n",
    "from scipy.stats import normaltest, shapiro, linregress\n",
    "from scipy.stats import ttest_1samp, ttest_ind, ttest_ind_from_stats, f_oneway\n",
    "from scipy.stats import mannwhitneyu\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from pingouin import ancova\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.colors import hsv_to_rgb, rgb_to_hsv, to_rgb\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, namedtuple\n",
    "import itertools as itt\n",
    "import copy\n",
    "\n",
    "\n",
    "# T-test using means and std errors. The closest scipy equivalent requires\n",
    "# means, std deviations, and number of observations.\n",
    "TestResult = namedtuple('TestResult', 'statistic pvalue')\n",
    "def ttest_from_err(mean1, stderr1, mean2, stderr2):\n",
    "    t = (mean1-mean2)/np.sqrt(stderr1**2+stderr2**2)\n",
    "    p = distributions.t.sf(np.abs(t), df) * 2\n",
    "\n",
    "# ANOVA test using the samples' means, std deviations, and sizes.\n",
    "# The closest scipy equivalent requires the original observations in each sample.\n",
    "def f_oneway_from_stats(means, stds, counts):\n",
    "    means  = np.asarray(list(means))\n",
    "    stds   = np.asarray(list(stds))\n",
    "    counts = np.asarray(list(counts), dtype=int)\n",
    "    k      = len(means) # number of samples\n",
    "    N      = np.sum(counts) # number of data points across all samples\n",
    "    mean   = np.sum(counts*means)/np.sum(counts) # mean of all samples taken together\n",
    "    ssb    = np.sum(counts*(means-mean)**2) # sum of squares between samples\n",
    "    ssw    = np.sum((counts)*stds**2) # sum of squares within samples\n",
    "    F      = (ssb/(k-1)) / (ssw/(N-k))\n",
    "    pval   = 1 - scipy.stats.f.cdf(F, k-1, N-k)\n",
    "    return TestResult(statistic=F, pvalue=pval)\n",
    "\n",
    "# Mean and standard error.\n",
    "def mean_sem(x, axis=None):\n",
    "    return np.nanmean(x, axis=axis),scipy.stats.sem(x, axis=axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5zjZYeZo3Ip"
   },
   "source": [
    "# Figure styling\n",
    "\n",
    "Fonts, line styles, color schemes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "names       = { 'sf':'Surface', 'pa':'PachÃ³n', 'mo':'Molino', \n",
    "                'ti':'Tinaja', 'sf-dark':'Surface in the dark' }\n",
    "populations = list(names.keys())\n",
    "\n",
    "plt.rc('font', size=16)\n",
    "plt.rc('axes',  labelsize=16)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "plt.rc('legend', fontsize=16)\n",
    "lw        = 2   # line width\n",
    "dpi       = 150 # figure output resolution\n",
    "alpha_err = 0.2 # transparency for std error halos\n",
    "leg_opt   = dict( borderpad=0.3, labelspacing=0.2, handlelength=1.5,\n",
    "                  handletextpad=0.5, borderaxespad=0.2, fontsize=15 ) # legend options\n",
    "err_opt   = dict( lw=lw, elinewidth=lw, capthick=lw, capsize=5, barsabove=False ) # errorbar plot options\n",
    "dashes    = dict(zip(populations, [(2,2), (3,1,1,1), (3,1,1,1,1,1), (1,1), (3,1)]))\n",
    "\n",
    "def create_color_shades(rgb, gray=False):\n",
    "    hsv = np.array([rgb_to_hsv(rgb)]*4)\n",
    "    hsv[:,0] += np.array([-1,0,1,2])*0.02    # Slight hue gradient.\n",
    "    hsv[:,1]  = np.array([0.5,0.6,0.9,1])    # Saturation gradient.\n",
    "    hsv[:,2]  = np.array([0.9,0.75,0.5,0.2]) # Value gradient.\n",
    "    if gray:\n",
    "        hsv[:,1] = 0\n",
    "        hsv[:,2]  = np.array([0.6,0.4,0.2,0]) # Value gradient.\n",
    "    return np.array(list(map(hsv_to_rgb,hsv)))\n",
    "\n",
    "def create_color_dictionaries(color_list, color_matrix, populations=populations):\n",
    "    color_dict1  = dict(zip( populations, color_list )) # One shade per population.\n",
    "    color_dict4  = { (pop,n):color_matrix[i,j] for i,pop in enumerate(populations) for j,n in enumerate([1,2,5,10]) }\n",
    "    # Color map interpolating between white and the default shade.\n",
    "    color_maps   = {}\n",
    "    for k,c in color_dict1.items():\n",
    "        # First max out saturation so colors \"pop\" a bit more, unless it's a grayscale family (s=0).\n",
    "        c = rgb_to_hsv(c)\n",
    "        if c[1]>0:\n",
    "            c = hsv_to_rgb((c[0],1,c[2]))\n",
    "        else:\n",
    "            c = hsv_to_rgb((c[0],0,0.1))\n",
    "        color_maps[k] = LinearSegmentedColormap.from_list(k,[c,(1,1,1)][::-1])\n",
    "    return dict( color_dict1=color_dict1, color_dict4=color_dict4, color_maps=color_maps )\n",
    "\n",
    "def visualize_color_scheme(color_list, color_matrix, title=None, ax=None):\n",
    "    cl  = color_list.reshape((-1,1,3))\n",
    "    mat = np.concatenate([color_matrix,np.ones_like(cl),cl],axis=1)\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax.imshow(mat)\n",
    "    ax.set_xticks(range(6))\n",
    "    ax.set_xticklabels(['1','2','3','4','','default'])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(title, pad=10)\n",
    "\n",
    "# Adam's color scheme.\n",
    "color_matrix  = [ [ '#AADFFC', '#689BB7', '#315C72', '#09232F' ],  \n",
    "                  [ '#FC7940', '#BF5428', '#823413', '#491702' ],\n",
    "                  [ '#3AFAF2', '#4FB1A8', '#406E67', '#22332E' ],\n",
    "                  [ '#F890A2', '#C75778', '#8C264E', '#4C0225' ],\n",
    "                  [ '#59DA7A', '#FFFFFF', '#FFFFFF', '#0F3B1C' ] ]\n",
    "color_matrix  = np.array([ [to_rgb(c) for c in C] for C in color_matrix ])\n",
    "color_list    = color_matrix[:,1].copy()\n",
    "color_list[4] = color_matrix[4,-1]\n",
    "color_schemes = { 'adam': (color_list,color_matrix) }\n",
    "\n",
    "# Scheme build on matplotlib's default line colors.\n",
    "color_list = np.array(list(map(to_rgb, ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd'])))\n",
    "color_matrix = np.array([create_color_shades(c) for c in color_list])\n",
    "color_schemes['mpl_'] = (color_list,color_matrix)\n",
    "\n",
    "# More matplotlib-based color schemes.\n",
    "for k in ['tab20','tab20b','tab20c']:\n",
    "    # Use the color scheme as-is.\n",
    "    color_matrix = np.array(plt.get_cmap(k).colors).reshape((5,4,3))[:,::-1,:]\n",
    "    color_list = color_matrix[:,-1,:].copy()\n",
    "    color_schemes[k] = (color_list,color_matrix)\n",
    "    # Keep each family's central hue, but apply custom recipe to create the shades within each family.\n",
    "    color_list = np.array(plt.get_cmap(k).colors[::4])\n",
    "    color_matrix = np.array([create_color_shades(c) for c in color_list])\n",
    "    if k=='tab20c':\n",
    "        color_matrix[4] = create_color_shades(color_list[4], gray=True)\n",
    "    color_schemes[k+'_'] = (color_list,color_matrix)\n",
    "\n",
    "# # Visualize every scheme under consideration.\n",
    "# nc = 4\n",
    "# nr = np.math.ceil(len(color_schemes)/nc)\n",
    "# fig,axs = plt.subplots(nr, nc, figsize=(4*nc,4*nr), gridspec_kw=dict(wspace=0.5))\n",
    "# for ax in axs.flatten():\n",
    "#     ax.axis('off')\n",
    "# for i,k in enumerate(color_schemes.keys()):\n",
    "#     visualize_color_scheme(*color_schemes[k], title=k, ax=axs[i//nc,i%nc])\n",
    "\n",
    "# Pick a scheme to use in the rest of the notebook.\n",
    "globals().update(create_color_dictionaries(*color_schemes['mpl_']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_data = pickle.load(open('figure-data.pik','rb'))\n",
    "# print(figure_data['fig1'].keys())\n",
    "globals().update(figure_data['fig1'])\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12,7.5))\n",
    "axs = axs.T\n",
    "\n",
    "# Video snapshots.\n",
    "for i in range(2):\n",
    "    ax = axs[0,i]\n",
    "    sf_track = mpimg.imread(f'assets/fig_snapshot-{[\"surface\",\"pachon\"][i]}.png')\n",
    "    ax.imshow(sf_track)\n",
    "    ax.axis('off')\n",
    "\n",
    "# Density and nematic OP.\n",
    "for i in range(2):\n",
    "    ax = axs[1,i]\n",
    "    Q  = [density,nematic][i]\n",
    "    for pop in Q.keys():\n",
    "        mu,err = mean_sem(Q[pop], axis=0)\n",
    "        ax.plot(bin_centers, mu, label=names[pop], \n",
    "                color=color_dict1[pop], lw=lw)\n",
    "        ax.fill_between(bin_centers, mu-err, mu+err, \n",
    "                        color=color_dict1[pop], alpha=alpha_err, lw=0)\n",
    "    ax.locator_params(axis='y', nbins=3)\n",
    "    for y in [-1,0,1]:\n",
    "        ax.axhline(y=y,color='k',dashes=(4,4),lw=0.5)\n",
    "    ax.set_xlim(0,55)\n",
    "    ax.set_xlabel('Distance from the wall (cm)')\n",
    "\n",
    "ax = axs[1,0]\n",
    "# ax.set_ylim(0,5.7e-4)\n",
    "ax.set_ylim(0,9e-4)\n",
    "ax.set_yticks([0,0.0004,0.0008])\n",
    "ax.set_ylabel('Area density')\n",
    "\n",
    "ax = axs[1,1]\n",
    "ax.set_ylim(-1.1,0.55)\n",
    "ax.set_yticks([-1,0])\n",
    "ax.set_ylabel('Nematic order\\nparameter')\n",
    "\n",
    "# Legend.\n",
    "plt.tight_layout()\n",
    "axs[2,1].set_visible(False)\n",
    "axs[1,1].legend(loc='center', bbox_to_anchor=(1.85,0.5),\n",
    "                borderpad=1, framealpha=0.5, edgecolor='k', fancybox=True)\n",
    "\n",
    "# Median distance to the wall.\n",
    "ax   = axs[2,0]\n",
    "med  = [ (k,x) for k,X in median.items() for x in X]\n",
    "med  = pd.DataFrame(med, columns=['Population', 'Median distance\\nfrom the wall (cm)'])\n",
    "data = dict(x='Population', y='Median distance\\nfrom the wall (cm)', data=med, ax=ax)\n",
    "palette = [ v+0.2*(1-v) for v in color_dict1.values()]\n",
    "sns.violinplot(inner=None, ec='None', palette=palette, cut=2, **data)\n",
    "sns.stripplot(size=5, jitter=0.1, color='k', **data)\n",
    "# ax.set_xlabel('')\n",
    "\n",
    "y0 = 55.5/np.sqrt(2)\n",
    "ax.axhline(y0, color='k', dashes=(4,4))\n",
    "ax.text(3.5, y0+0.3, 'uniform area density ', fontsize=12, ha='right', va='bottom')\n",
    "\n",
    "def draw_bracket(txt, x1, x2, y, dx=0, dy=0.8, ax=ax):\n",
    "    # dy = ax.transAxes.inverted([0,dy_])\n",
    "    ax.plot([x1+dx,x1+dx,x2-dx,x2-dx], [y-dy,y,y,y-dy], color='k', lw=0.5)\n",
    "    ax.text((x1+x2)/2, y-1, txt, va='bottom', ha='center')\n",
    "draw_bracket('***', 0, 1, 24)\n",
    "draw_bracket('**', 0, 2, 28)\n",
    "draw_bracket('*', 0, 3, 32)\n",
    "ax.set_ylim(0, 46)\n",
    "\n",
    "# Label each panel.\n",
    "for i,c in enumerate('abcde'):\n",
    "    ax = axs[i//2,i%2]\n",
    "    ax.text(0.02, 0.98, c, transform=ax.transAxes, fontsize=24, weight='bold', va='top')\n",
    "\n",
    "plt.savefig('fig1.png', dpi=dpi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test normality.\n",
    "print('Shapiro test:')\n",
    "for k,X in median.items():\n",
    "    print(f'p[{k}] = {shapiro(X)[1]}')\n",
    "# print(f'cave: p = {shapiro(df_cf)[1]}')\n",
    "\n",
    "print('\\nMann-Whitney test:')\n",
    "for k in ['pa','mo','ti']:\n",
    "#     p = ttest_ind(median['sf'],median[k]).pvalue\n",
    "#     print(f'T-test sf-{k}: p = {p}')\n",
    "    p = mannwhitneyu(median['sf'],median[k]).pvalue\n",
    "    print(f'p[sf-{k}] = {p}')\n",
    "\n",
    "# # If the hypothesis is that there's at least one inter-population difference, \n",
    "# # use a multiple test correction.\n",
    "# # However here the hypothesis is that all three cave populations are different \n",
    "# # from the surface population. If anything the bar should be lowered.\n",
    "# P = [ mannwhitneyu(median['sf'],median[k]).pvalue for k in ['pa','mo','ti'] ]\n",
    "# multipletests(P) # , method='holm-sidak') # 'sidak') # 'bonferroni') # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we test normality on the combined sample that \n",
    "# will go into the T or Mann-Whitney test\n",
    "\n",
    "for k in ['pa','mo','ti']:\n",
    "    m1, m2 = median['sf'].tolist(), median[k].tolist()\n",
    "    p_sh = shapiro(m1+m2).pvalue\n",
    "    p_tt = ttest_ind(m1,m2).pvalue\n",
    "    p_mw = mannwhitneyu(m1,m2).pvalue\n",
    "    fmt  = '.1g'\n",
    "    print(f'sf-{k}: p[Shapiro]={p_sh:{fmt}}, p[T-test]={p_tt:{fmt}}, p[Mann-Whitney]={p_mw:{fmt}}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-6RIbnbo3JK"
   },
   "source": [
    "# Figure 2\n",
    "\n",
    "While the cave fish tend to maintain an active swim state in our arena, regardless of group size, surface fish tend to stop swimming when they are alone or in small groups. In this figure we show the impact of this on the distribution of swim speed and consider the impact of inactivity across group size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_data = pickle.load(open('figure-data.pik','rb'))\n",
    "# print(figure_data['fig2'].keys())\n",
    "globals().update(figure_data['fig2'])\n",
    "\n",
    "fig, axs = plt.subplots( nrows=1, ncols=2, figsize=(8,3.5), \n",
    "                         gridspec_kw=dict(wspace=0.5, bottom=0.2, top=0.95, right=0.95) )\n",
    "\n",
    "ax = axs[0]\n",
    "x  = speed_distribution['bin_centers']\n",
    "for i,n in enumerate([1,2,5]): # Loop over group size.\n",
    "    H      = speed_distribution['sf',n]\n",
    "    mu,err = mean_sem(H, axis=0)\n",
    "    ax.plot(x, mu, label=n, color=color_dict4['sf',n], lw=lw)\n",
    "    ax.fill_between(x, mu-err, mu+err, color=color_dict4['sf',n], alpha=alpha_err, lw=0)\n",
    "ax.set_xlabel('Speed (cm/s)')\n",
    "ax.set_ylabel('Probability density')\n",
    "ax.set_xlim(0,50)\n",
    "ax.set_ylim(0,None)\n",
    "ax.legend(**leg_opt)\n",
    "\n",
    "ax     = axs[1]\n",
    "n_list = [1,2,5,10]\n",
    "opt    = lambda pop: dict( lw=lw, elinewidth=lw, capsize=5, alpha=1,\n",
    "                           color=color_dict1[pop], label=pop, dashes=dashes[pop] )\n",
    "F = inactive_fraction\n",
    "n_list = [1,2,5,10]\n",
    "for pop in populations[:-1]:\n",
    "    mu    = np.array([np.nanmean(F[pop,n], axis=0) for n in n_list])\n",
    "    std   = np.array([np.nanstd(F[pop,n], axis=0) for n in n_list])\n",
    "    count = len(F[pop,n])\n",
    "#     count = np.count_nonzero(np.isfinite(F[pop,n]))\n",
    "    err   = std / np.sqrt(count-1)\n",
    "#     ax.errorbar(n_list, _mu, yerr=_err, color=color_dict1[pop], label=pop, \n",
    "#                 dashes=dashes[pop], **err_opt)\n",
    "    opt   = err_opt\n",
    "    opt.update(lw=0)\n",
    "    ax.errorbar(n_list, mu, yerr=err, color=color_dict1[pop], **opt)\n",
    "    ax.plot(n_list, mu, color=color_dict1[pop], dashes=dashes[pop], lw=lw, label=pop)\n",
    "ax.set_ylim(0.6,1.08)\n",
    "ax.set_xlabel('Group size')\n",
    "ax.set_ylabel('Fraction of the\\ntime active')\n",
    "ax.set_xticks(n_list)\n",
    "leg_opt.update(dict(handlelength=1.5))\n",
    "ax.legend(**leg_opt)\n",
    "\n",
    "# Label each panel.\n",
    "for i,c in enumerate('ab'):\n",
    "    ax = axs[i%2]\n",
    "    ax.text(0.02, 0.98, c, transform=ax.transAxes, fontsize=24, weight='bold', va='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig2.png', dpi=dpi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Work in progress]\n",
    "\n",
    "Figures above use trilab-tracker data.\n",
    "Figures below use Adam's figure data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_cL6nPXo3Jd"
   },
   "source": [
    "# Figure 3\n",
    "\n",
    "Now let's take a look at the distribution of speeds after the activity cut. First we can grab histograms from the pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = trial_store['histograms-vcut']\n",
    "means = trial_store['means-vcut']\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(12,4))\n",
    "axs = axs.flatten()\n",
    "\n",
    "n_list = [1,2,5,10]\n",
    "for i,pop in enumerate(['SF','Pa']):\n",
    "    ax  = axs[i]\n",
    "    ax.set_title(names[pop])\n",
    "    ax.set_xlabel('Speed (cm/s)')\n",
    "    ax.set_ylabel('Probability density')\n",
    "    x   = H['speed','bin_centers']\n",
    "    for n in n_list:\n",
    "        y   = np.mean(H[pop,n,'speed'], axis=0)\n",
    "        err = np.std(H[pop,n,'speed'], axis=0)/np.sqrt(len(H[pop,n,'speed'])-1)\n",
    "        ax.plot(x, y, label=n, color=color_dict4[pop,n], lw=lw)\n",
    "        ax.fill_between(x, y-err, y+err, color=color_dict4[pop,n], alpha=alpha_err, lw=0, zorder=-5)\n",
    "#         ax.fill_between(x, y-err, y+err, color=color_dict4[pop,n], alpha=0.7, lw=0, label=n)\n",
    "    ax.legend(**leg_opt)\n",
    "    ax.set_xlim(0,75)\n",
    "    ax.set_ylim(0,1.1*ax.get_ylim()[1])\n",
    "    ax.locator_params('y',nbins=4)\n",
    "\n",
    "ax = axs[2]\n",
    "ms_stats = {}\n",
    "for pop in populations[:-1]:\n",
    "#     xy = [(n,m) for n in n_list for m in means[pop,n,'speed'][:,0]]\n",
    "#     ax.scatter(*zip(*xy), color=color_dict1[pop], s=3)\n",
    "    MS  = [means[pop,n,'speed'][:,0] for n in n_list]\n",
    "    y   = [np.mean(ms) for ms in MS]\n",
    "    err = [np.std(ms)/np.sqrt(len(ms)-1) for ms in MS]\n",
    "    ax.errorbar(n_list, y, yerr=err, color=color_dict1[pop], label=pop, alpha=0.7, **err_opt) # , dashes=dashes[pop]\n",
    "ax.set_xlabel('Group size')\n",
    "ax.set_ylabel('Mean speed\\nwhen active')\n",
    "ax.set_xticks(n_list)\n",
    "ax.set_ylim(0,30)\n",
    "ax.locator_params(axis='y', nbins=4)\n",
    "ax.legend(**leg_opt)\n",
    "\n",
    "# Label each panel.\n",
    "for i,c in enumerate('abc'):\n",
    "    ax = axs[i] # [i//2,i%2] \n",
    "    ax.text(0.02, 0.98, c, transform=ax.transAxes, fontsize=24, weight='bold', va='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig3.png', dpi=dpi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope,pvalue = [],[]\n",
    "fig,axs = plt.subplots(2, 2, figsize=(6,6))\n",
    "for ax,pop in zip(axs.flatten(),populations[:-1]):\n",
    "    x,y  = np.array([ (k[1],m) for k,M in means.items() if k[0]==pop and k[2]=='speed' for m in M[:,0] ]).T\n",
    "#     x,y  = np.array([ (n,m) for n in [1,2,5,10] for m in means[pop,n,'speed'][:,0] ]).T\n",
    "    ax.scatter(x, y, fc='None', ec=color_dict1[pop], lw=1, label=names[pop])\n",
    "    reg = linregress(x, y) #, alternative='less')\n",
    "    pvalue.append([pop, reg.pvalue])\n",
    "    slope.append([pop, reg.slope, reg.stderr, len(x)])\n",
    "    ax.plot(x, reg.slope*x+reg.intercept, color=color_dict1[pop])\n",
    "    ax.set_title(names[pop])\n",
    "# fig.legend(loc='center left', bbox_to_anchor=(0.95,0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'p-values for a negative slope:')\n",
    "for pop,pval in pvalue:\n",
    "    print(f'  {pop}: {pval}')\n",
    "\n",
    "ax = plt.gca()\n",
    "n,s,e,no = zip(*slope)\n",
    "ax.errorbar(n, s, yerr=e, **err_opt)\n",
    "ax.set_xticklabels(names.values())\n",
    "ax.set_ylabel('Population')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = trial_store['means-vcut']\n",
    "df = []\n",
    "for k,M in means.items():\n",
    "    if len(k)==3 and k[2]=='speed' and k[0] in populations[:-1]:\n",
    "        for m in M:\n",
    "            df.append([k[0],k[1],m[0]])\n",
    "df = pd.DataFrame(df, columns=['Population','n','Mean Speed'])\n",
    "# display(df)\n",
    "\n",
    "for p1,p2 in itt.combinations(populations[:-1],2):\n",
    "    I   = (df['Population']==p1)|(df['Population']==p2)\n",
    "    res = ancova(data=df[I], dv='Mean Speed', covar='n', between='Population')\n",
    "#     display(res)\n",
    "    p   = float(res.loc[res['Source']=='Population','p-unc'])\n",
    "    print(f'{p1}-{p2}: {p}')\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1,p2 = ['SF','Pa']\n",
    "I   = (df['Population']==p1)|(df['Population']==p2)\n",
    "# display(df[I])\n",
    "df[df['Population']=='SF'].plot(x='n', y='Mean Speed', kind='scatter', ax=plt.gca())\n",
    "df[df['Population']=='Pa'].plot(x='n', y='Mean Speed', kind='scatter', ax=plt.gca(), color='r')\n",
    "# df[I].groupby('Population').plot(x='n', y='Mean Speed', lw=0, marker='o', ax=plt.gca())\n",
    "\n",
    "res = ancova(data=df[I], dv='Mean Speed', covar='n', between='Population')\n",
    "display(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,s,e,no = zip(*slope)\n",
    "for i in range(1,4):\n",
    "    p = ttest_ind_from_stats(s[0],e[0],2, s[i],e[i],2).pvalue\n",
    "    print(f'SF-{n[i]}: {p}')\n",
    "    p = ttest_ind_from_stats(s[0],e[0],no[0]-2, s[i],e[i],no[i]-2).pvalue\n",
    "    print(f'SF-{n[i]}: {p}')\n",
    "    print()\n",
    "\n",
    "pd.DataFrame(slope, columns=['Population','slope','err','n_obs'])\n",
    "# pairwise_tukeyhsd("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4QLMoMoo3KG"
   },
   "source": [
    "## Supplement to Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list = [1,2,5,10]\n",
    "H = trial_store['histograms-vcut']\n",
    "means = trial_store['means-vcut']\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(8,7))\n",
    "\n",
    "for i,pop in enumerate(populations[:-1]):\n",
    "    ax  = axs[i//2,i%2]\n",
    "    ax.set_title(names[pop])\n",
    "    ax.set_xlabel('Speed (cm/s)')\n",
    "    ax.set_ylabel('Probability density')\n",
    "    x   = H['speed','bin_centers']\n",
    "    for n in n_list:\n",
    "        y   = np.mean(H[pop,n,'speed'], axis=0)\n",
    "        err = np.std(H[pop,n,'speed'], axis=0)/np.sqrt(len(H[pop,n,'speed'])-1)\n",
    "        ax.plot(x, y, label=n, color=color_dict4[pop,n], lw=lw)\n",
    "        ax.fill_between(x, y-err, y+err, color=color_dict4[pop,n], alpha=alpha_err, lw=0, zorder=-5)\n",
    "    ax.legend(**leg_opt)\n",
    "    ax.set_xlim(0,75)\n",
    "    ax.set_ylim(0,None)\n",
    "    ax.locator_params('y',nbins=4)\n",
    "    ax.set_ylim(0,1.1*ax.get_ylim()[1])\n",
    "\n",
    "# Label each panel.\n",
    "for i,c in enumerate('abcd'):\n",
    "    ax = axs[i//2,i%2] \n",
    "    ax.text(0.02, 0.98, c, transform=ax.transAxes, fontsize=24, weight='bold', va='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(fpath('SI-speeds.png'), dpi=dpi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3pZSmXjo3KK"
   },
   "source": [
    "Note that we only have single runs for Tinaja and Molino groups of 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__234yG3o3KL"
   },
   "source": [
    "# Figure 4\n",
    "\n",
    "In this figure, we focus on the distributions of turning behavior across type and group size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list = [1, 2, 5, 10]\n",
    "H = trial_store['histograms-vcut']\n",
    "\n",
    "# Set vertical line at the following x-coordinates\n",
    "xvline1 = 1\n",
    "xvline2 = 7\n",
    "alpha_vline = 0.67\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(8,8),\n",
    "                       gridspec_kw={'width_ratios': [8,20], 'wspace':0.6, 'hspace':0.5,\n",
    "                                    'right':0.95, 'top':0.95})\n",
    "for i,pop in enumerate(['SF','Pa']):\n",
    "    ax = axs[i,0]\n",
    "    ax.set_title(names[pop])\n",
    "    ax.set_xlabel('Angular speed (rad/s)')\n",
    "#     ax.set_ylabel('Probability density')\n",
    "    ax.set_ylabel('Time-based\\nprobability density')\n",
    "    x   = H['omega','bin_centers']\n",
    "    for n in n_list:\n",
    "        h   = H[pop,n,'omega']\n",
    "        y   = np.mean(h, axis=0)\n",
    "        err = np.std(h, axis=0)/np.sqrt(len(h)-1)\n",
    "        ax.plot(x, y, label=n, color=color_dict4[pop,n], lw=lw)\n",
    "        ax.fill_between(x, y-err, y+err, color=color_dict4[pop,n], alpha=alpha_err, lw=0, zorder=-5)\n",
    "    ax.set_xlim(0,8)\n",
    "    \n",
    "    ax = axs[i,1]\n",
    "    ax.set_title(names[pop])\n",
    "#     ax.set_ylabel('Probability density\\n'+r'$\\times$ Angular speed')\n",
    "    ax.set_ylabel('Angle-based\\nprobability density')\n",
    "    x   = H['omega','bin_centers']\n",
    "    for n in n_list:\n",
    "        h   = H[pop,n,'omega']\n",
    "        y   = np.mean(h, axis=0)\n",
    "        err = np.std(h, axis=0)/np.sqrt(len(h)-1)\n",
    "        ax.plot(x, x*y, label=n, color=color_dict4[pop,n], lw=lw)\n",
    "        ax.fill_between(x, x*(y-err), x*(y+err), color=color_dict4[pop,n], alpha=alpha_err, lw=0, zorder=-5)\n",
    "    ax.set_xlim(0,20)\n",
    "    ax.legend(loc='upper right', **leg_opt)\n",
    "    \n",
    "for ax in axs.flatten():\n",
    "    for x in [1,7]:\n",
    "        ax.axvline(x, lw=0.7*lw, color='k', dashes=(4,4))\n",
    "    ax.set_xlabel('Angular speed (rad/s)')\n",
    "    ax.set_ylim(0,1.1*ax.get_ylim()[1])\n",
    "    ax.locator_params(axis='x', nbins=5)\n",
    "#     ax.legend(loc='upper right', **leg_opt)\n",
    "\n",
    "# Label each panel.\n",
    "for i,c in enumerate('abcd'):\n",
    "    ax = axs[i//2,i%2] \n",
    "    t = ax.text(0.05/(i%2+1), 0.98, c, transform=ax.transAxes, fontsize=24, weight='bold', va='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(fpath(\"fig4.png\"), dpi=dpi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRcpYuKDo3KQ"
   },
   "source": [
    "## Supplement to Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list = [1, 2, 5, 10]\n",
    "H = trial_store['histograms-vcut']\n",
    "\n",
    "# Set vertical line at the following x-coordinates\n",
    "xvlines = [1,7]\n",
    "alpha_vline = 0.67\n",
    "\n",
    "fig, axs = plt.subplots(nrows=4, ncols=2, figsize=(8,16),\n",
    "                       gridspec_kw={'width_ratios': [8,20], 'wspace':0.6, 'hspace':0.5,\n",
    "                                    'right':0.95, 'top':0.95})\n",
    "for i,pop in enumerate(populations[:-1]):\n",
    "    ax = axs[i,0]\n",
    "    ax.set_title(names[pop])\n",
    "    ax.set_xlabel('Angular speed (rad/s)')\n",
    "    ax.set_ylabel('Time-based\\nprobability density')\n",
    "    x   = H['omega','bin_centers']\n",
    "    for n in n_list:\n",
    "        h   = H[pop,n,'omega']\n",
    "        y   = np.mean(h, axis=0)\n",
    "        err = np.std(h, axis=0)/np.sqrt(len(h)-1)\n",
    "        ax.plot(x, y, label=n, color=color_dict4[pop,n], lw=lw)\n",
    "        ax.fill_between(x, y-err, y+err, color=color_dict4[pop,n], alpha=alpha_err, lw=0, zorder=-5)\n",
    "    ax.set_xlim(0,8)\n",
    "    \n",
    "    ax = axs[i,1]\n",
    "    ax.set_title(names[pop])\n",
    "    ax.set_ylabel('Angle-based\\nprobability density')\n",
    "    x   = H['omega','bin_centers']\n",
    "    for n in n_list:\n",
    "        h   = H[pop,n,'omega']\n",
    "        y   = np.mean(h, axis=0)\n",
    "        a   = 1/np.trapz(y, x) # Density normalization.\n",
    "        err = np.std(h, axis=0)/np.sqrt(len(h)-1)\n",
    "        ax.plot(x, a*x*y, label=n, color=color_dict4[pop,n], lw=lw)\n",
    "        ax.fill_between(x, a*x*(y-err), a*x*(y+err), color=color_dict4[pop,n], alpha=alpha_err, lw=0, zorder=-5)\n",
    "    ax.set_xlim(0,20)\n",
    "    ax.legend(loc='upper right', **leg_opt)\n",
    "    \n",
    "for ax in axs.flatten():\n",
    "    for x in xvlines:\n",
    "        ax.axvline(x, lw=0.7*lw, color='k', dashes=(4,4))\n",
    "    ax.set_xlabel('Angular speed (rad/s)')\n",
    "    ax.set_ylim(0,1.1*ax.get_ylim()[1])\n",
    "    ax.locator_params(axis='x', nbins=5)\n",
    "#     ax.legend(loc='upper right', **leg_opt)\n",
    "\n",
    "# Label each panel.\n",
    "for i,c in enumerate('abcdefgh'):\n",
    "    ax = axs[i//2,i%2] \n",
    "    ax.text(0.05/(i%2+1), 0.98, c, transform=ax.transAxes, fontsize=24, weight='bold', va='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(fpath(\"SI-turns.png\"), dpi=dpi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [ k for k in H.keys() if len(k)==3 and k[2]=='omega' ]\n",
    "bins = H['omega', 'bin_centers']\n",
    "# ranges = ((0,1),(1,6),(6,np.inf))\n",
    "ranges = ((0,0.5),(0.5,6),(6,np.inf))\n",
    "# ranges = ((0,1),(1,np.inf))\n",
    "II   = [ (np.absolute(bins)>=R[0])&(np.absolute(bins)<R[1]) for R in ranges ]\n",
    "# I1   = np.absolute(bins)<1\n",
    "# I3   = np.absolute(bins)>=6\n",
    "# I2   = ~(I1|I3)\n",
    "stats = {}\n",
    "for k in keys:\n",
    "    for j,I in enumerate(II):\n",
    "        h       = H[k].copy()\n",
    "        h[:,~I] = 0\n",
    "        stats[k[:2]+(j,'time')] = np.trapz(h, bins, axis=1)\n",
    "        a       = 1/np.trapz(H[k]*np.absolute(bins), bins, axis=1) # Density normalization.\n",
    "        stats[k[:2]+(j,'angle')] = a*np.trapz(h*np.absolute(bins), bins, axis=1)\n",
    "\n",
    "# range_labels = ['0-1', '1-6', '6+']\n",
    "range_labels = [ f'{r1}-{r2}' for r1,r2 in ranges ]\n",
    "N = [1,2,5,10]\n",
    "for q in ['time','angle']:\n",
    "    for j in range(len(ranges)):\n",
    "        for pop in populations[:-1]:\n",
    "            S = [ stats[pop,n,j,q] for n in N ]\n",
    "            y = [ np.mean(s) for s in S ]\n",
    "            e = [ np.std(s)/np.sqrt(len(s)-1) for s in S ]\n",
    "            plt.errorbar(N, y, e, label=f'{pop} {range_labels[j]}', color=color_dict1[pop], alpha=0.8, **err_opt)\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1.01,0.5))\n",
    "        plt.xticks([1,2,5,10])\n",
    "        plt.xlabel('Group size')\n",
    "        plt.ylim(0,1)\n",
    "        plt.ylabel(f'Fraction of {q}')\n",
    "    #     plt.tight_layout()\n",
    "        plt.show()\n",
    "    #     break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHwOwPtKo3KV"
   },
   "source": [
    "# Figure 5\n",
    "\n",
    "We're interested in the collective behavior. To summarize the collective schooling and/or shoaling behavior of these fish, we measure relative distance and relative angle between all pairs of fish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_binned = trial_store['distance-alignment']\n",
    "x = da_binned['x_edges']\n",
    "y = da_binned['y_edges']\n",
    "\n",
    "gridspec=dict(wspace=0.4, hspace=0.4, left=0.02, right=0.98, bottom=0.08, top=0.94)\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12,8), gridspec_kw=gridspec)\n",
    "fig.tight_layout()\n",
    "\n",
    "# Label each panel.\n",
    "# Note: with `transform=ax.transAxes`, the labels move if the axes object is later resized.\n",
    "# Doing the coordinate transform explicitly (after calling `tight_layout`) avoids that,  \n",
    "# thus keeping the labels on a regular grid.\n",
    "for i,c in enumerate('abcdef'):\n",
    "    ax = axs[i//3,i%3] \n",
    "    xy = fig.transFigure.inverted().transform(ax.transAxes.transform([0.02,0.98]))\n",
    "    ax.text(*xy, c, transform=fig.transFigure, fontsize=24, weight='bold', va='top')\n",
    "\n",
    "# First column: schematics.\n",
    "for i,fn in enumerate(['fig_schematic_pair-angle.png','fig_schematic_collective-behavior.png']):\n",
    "    axs[i,0].imshow(mpimg.imread(fpath(fn)))\n",
    "    axs[i,0].axis('off')\n",
    "bbox = axs[1,0].get_position()\n",
    "bbox.y0,bbox.y1 = np.array([bbox.y0,bbox.y1]) - 0.04\n",
    "axs[1,0].set_position(bbox)\n",
    "\n",
    "for i,pop in enumerate(['SF','Pa']):\n",
    "    for j,n in enumerate([2,10]):\n",
    "        ax  = axs[j,i+1]\n",
    "        z   = da_binned[pop,n].T\n",
    "        ax.pcolormesh(x, y, z, cmap = color_maps[pop], vmin=0, vmax=np.max(z))\n",
    "        ax.set_xlim(x[0], x[-1])\n",
    "        ax.set_ylim(y[0], y[-1])\n",
    "        ax.set_yticks([0,30,60,90,120,150,180])\n",
    "        ax.set_ylabel(\"Pair angle (deg)\")\n",
    "        ax.set_xlabel(\"Pair distance (cm)\")\n",
    "        ax.set_title(f'{n} {names[pop]}')\n",
    "\n",
    "# Wall following prediction (arches).\n",
    "D     = 111  # tank diameter\n",
    "D_    = 103 # effective tank diameter (wall-following diameter)\n",
    "d     = np.arange(0,D+1,1)\n",
    "theta = (180/np.pi) * np.arccos(1 - 2*(d/D_)**2)\n",
    "opt   = dict(lw=1.5, alpha=0.5, color='k', dashes=(4,4))\n",
    "for i in range(2):\n",
    "    axs[i,2].plot(d, theta, **opt)\n",
    "    axs[i,2].plot(d, 180-theta, **opt)\n",
    "\n",
    "\n",
    "fout = \"fig5.png\"\n",
    "plt.savefig(fpath(\"fig5.png\"), dpi=dpi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IumiBL8UVqyD"
   },
   "source": [
    "## Density of proximities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "executionInfo": {
     "elapsed": 1305,
     "status": "ok",
     "timestamp": 1601953907377,
     "user": {
      "displayName": "adam patch",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFTzinZj911kG-IW63EFiF81lcOiS3MHHUCKcA5w=s64",
      "userId": "09517649083356287765"
     },
     "user_tz": 240
    },
    "id": "M7xIsW26o3Kl",
    "outputId": "71a1d612-634d-47b1-c8fa-bfe310685492"
   },
   "outputs": [],
   "source": [
    "# for n in [2,10]:\n",
    "#     bc = da_binned['x_centers']\n",
    "#     h_dist = np.sum(da_binned['SF',n], axis=1)/np.sum(da_binned['SF',n])\n",
    "#     fig, ax1 = plt.subplots()\n",
    "#     plt.title(f\"Relative distance for {n} Surface Fish\")\n",
    "#     ax1.plot(bc,h_dist,c='blue',alpha=0.6,lw=3)\n",
    "#     ax1.set_ylabel(\"Probability density\",c='blue')\n",
    "    \n",
    "#     ax2 = ax1.twinx()\n",
    "#     ax2.plot(bc,np.cumsum(h_dist), '--', c='brown', alpha=0.6,lw=3)\n",
    "#     ax2.set_ylabel(\"Cumulative\", c='brown')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rR-DI2EAo3Kv"
   },
   "source": [
    "## Supplement to Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "da_binned = trial_store['distance-alignment']\n",
    "x = da_binned['x_edges']\n",
    "y = da_binned['y_edges']\n",
    "\n",
    "for n in [2,5,10]:\n",
    "    gridspec = dict(wspace=0.4, hspace=0.4, left=0.1, right=0.97, bottom=0.08, top=0.94)\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(8,8), gridspec_kw=gridspec)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Label each panel.\n",
    "    for i,c in enumerate('abcd'):\n",
    "        ax = axs[i//2,i%2] \n",
    "        ax.text(0.02, 0.98, c, transform=ax.transAxes, fontsize=24, weight='bold', va='top')\n",
    "\n",
    "    for i,pop in enumerate(populations[:-1]):\n",
    "        ax  = axs[i//2,i%2]\n",
    "        z   = da_binned[pop,n].T\n",
    "        ax.pcolormesh(x, y, z, cmap = color_maps[pop], vmin=0, vmax=np.max(z))\n",
    "        ax.set_xlim(x[0], x[-1])\n",
    "        ax.set_ylim(y[0], y[-1])\n",
    "        ax.set_yticks([0,30,60,90,120,150,180])\n",
    "        ax.set_ylabel(\"Pair angle (deg)\")\n",
    "        ax.set_xlabel(\"Pair distance (cm)\")\n",
    "        ax.set_title(f'{n} {names[pop]}')\n",
    "\n",
    "#         if pop!='SF':\n",
    "#             # Wall following prediction (arches).\n",
    "#             D     = 111  # tank diameter\n",
    "#             D_    = 103 # effective tank diameter (wall-following diameter)\n",
    "#             d     = np.arange(0,D+1,1)\n",
    "#             theta = (180/np.pi) * np.arccos(1 - 2*(d/D_)**2)\n",
    "#             opt   = dict(lw=1.5, alpha=0.5, color='k', dashes=(4,4))\n",
    "#             for i in range(2):\n",
    "#                 ax.plot(d, theta, **opt)\n",
    "#                 ax.plot(d, 180-theta, **opt)\n",
    "    \n",
    "    plt.savefig(fpath(f\"SI_collective-n{n:02}.png\"), dpi=dpi)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKFnj8PUo3K1"
   },
   "source": [
    "# Figure 6\n",
    "\n",
    "In this figure, we consider surface fish in a dark tank and compare some aspects of their behavior to cavefish.\n",
    "\n",
    "First, we need to connect with several dictionary entries from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data.\n",
    "h_dark     = trial_store['dark-histograms-vcut']\n",
    "means_dark = trial_store['dark-means-vcut']\n",
    "da_binned  = trial_store['distance-alignment']\n",
    "da_binned['SF-dark',10] = trial_store['dark-distance-alignment']\n",
    "h_theta    = trial_store['pair-angle-slice']['h_theta']\n",
    "cos_mean   = trial_store['pair-angle-slice']['cos_mean']\n",
    "\n",
    "\n",
    "# Create figure.\n",
    "gridspec = dict(wspace=0.4, hspace=0.4, left=0.07, right=0.99, bottom=0.08, top=0.9)\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(12,3.8), gridspec_kw=gridspec)\n",
    "fig.tight_layout()\n",
    "inset_fontsize = 12\n",
    "err_opt2 = dict(lw=lw, elinewidth=0.7*lw, capsize=2) # inset error bar options\n",
    "\n",
    "\n",
    "# Label each panel.\n",
    "for i,c in enumerate('abc'):\n",
    "    ax = axs[i] \n",
    "    ax.text(0.02, 0.98, c, transform=ax.transAxes, fontsize=24, weight='bold', va='top')\n",
    "\n",
    "\n",
    "# Left panel: speed distribution.\n",
    "ax = axs[0]\n",
    "D  = 111 # tank diameter\n",
    "pop = 'SF-dark'\n",
    "for n in [1,10]:\n",
    "    x = h_dark['speed','bin_centers']\n",
    "    h = h_dark['SF',n,'speed']\n",
    "    y = np.mean(h, axis=0)\n",
    "    err = np.std(h, axis=0)/np.sqrt(len(h)-1)\n",
    "    ax.plot(x, y, label=n, color=color_dict4[pop,n], lw=lw)\n",
    "    ax.fill_between(x, y-err, y+err, color=color_dict4[pop,n], alpha=alpha_err, lw=0, zorder=-5)\n",
    "ax.set_xlim(0,65)\n",
    "ax.set_ylim(0,1.1*ax.get_ylim()[1])\n",
    "ax.locator_params('y',nbins=5)\n",
    "ax.set_xlabel('Speed (cm/s)')\n",
    "ax.set_ylabel('Probability density')\n",
    "# leg_opt   = dict( borderpad=0.3, labelspacing=0.2, handlelength=1.5,\n",
    "#                   handletextpad=0.5, borderaxespad=0.2, fontsize=15 )\n",
    "l_opt = dict( borderpad=0.3, labelspacing=0.2, handlelength=1,\n",
    "              handletextpad=0.5, borderaxespad=0.2, fontsize=15 )\n",
    "ax.legend(loc='lower left', **l_opt)\n",
    "ax.set_title(names[pop])\n",
    "\n",
    "\n",
    "# Left panel inset: mean speed vs group size.\n",
    "x0,y0,x1,y1 = axs[0].get_position()._points.flatten()\n",
    "x0_,y0_     = x0+0.45*(x1-x0), y0+0.4*(y1-y0)\n",
    "ax_         = fig.add_axes([x0_, y0_, x1-x0_-0.003, y1-y0_-0.01])\n",
    "# Prepare data.\n",
    "process_means = lambda n,m: (n, np.mean(m), np.std(m)/np.sqrt(len(m)-1))\n",
    "  # Surface in the light.\n",
    "x,y,err = np.array([ process_means(n, trial_store['means-vcut']['SF',n,'speed'][:,0]) for n in [1,2,5,10] ]).T\n",
    "ax_.errorbar(x, y, yerr=err, color=color_dict1['SF'], dashes=dashes['SF'], label='Surface, light', **err_opt2)\n",
    "  # Surface in the dark.\n",
    "x,y,err = np.array([ process_means(n, means_dark['SF',n,'speed'][:,0]) for n in [1,10] ]).T\n",
    "ax_.errorbar(x, y, yerr=err, color=color_dict1['SF-dark'], dashes=dashes['SF-dark'], label='Surface, dark', **err_opt2)\n",
    "  # All cavefish.\n",
    "# x,y,err = np.array([ process_means(n, trial_store['means-vcut']['all-cavefish',n][:,0]) for n in [1,10] ]).T\n",
    "x,y,err = np.array([ process_means(n, \n",
    "              np.concatenate([trial_store['means-vcut'][pop,n,'speed'][:,0] \n",
    "                 for pop in ['Pa','Ti','Mo']])) for n in [1,2,5,10] ]).T\n",
    "ax_.errorbar(x, y, yerr=err, color='#AA0000', dashes=dashes['Pa'], label='All cavefish', **err_opt2)\n",
    "ax_.set_xlim(0,11)\n",
    "ax_.set_ylim(0,None)\n",
    "ax_.set_xticks([1,2,5,10])\n",
    "ax_.set_xlabel('Group size', fontsize=inset_fontsize, labelpad=0)\n",
    "ax_.set_ylabel('Mean speed (cm/s)', fontsize=inset_fontsize, labelpad=0)\n",
    "l_opt = dict( borderpad=0.3, labelspacing=0.2, handlelength=1.5,\n",
    "              handletextpad=0.5, borderaxespad=0.2, fontsize=inset_fontsize, frameon=False )\n",
    "ax_.legend(**l_opt)\n",
    "\n",
    "\n",
    "# Middle panel: distance-angle probability heatmap.\n",
    "ax = axs[1]\n",
    "n,pop = 10,'SF-dark'\n",
    "x     = trial_store['distance-alignment']['x_edges']\n",
    "y     = trial_store['distance-alignment']['y_edges']\n",
    "z     = trial_store['distance-alignment'][pop,n].T\n",
    "ax.pcolormesh(x, y, z, cmap = color_maps[pop], vmin=0, vmax=np.max(z))\n",
    "ax.set_xlim(x[0], x[-1])\n",
    "ax.set_ylim(y[0], y[-1])\n",
    "ax.set_yticks([0,30,60,90,120,150,180])\n",
    "ax.set_ylabel(\"Pair angle (deg)\")\n",
    "ax.set_xlabel(\"Pair distance (cm)\")\n",
    "ax.set_title(f'{n} {names[pop]}')\n",
    "\n",
    "\n",
    "# Right panel: angle probability when close.\n",
    "ax   = axs[2]\n",
    "n    = 10 # group size\n",
    "d0   = 10 # distance threshold\n",
    "bins = np.linspace(0,180,201)\n",
    "x    = (bins[1:]+bins[:-1])/2\n",
    "for pop in populations:\n",
    "    Y   = trial_store['pair-angle-slice']['h_theta'][pop] *np.pi/180\n",
    "    y   = np.mean(Y, axis=0)\n",
    "    err = np.std(Y, axis=0)/np.sqrt(Y.shape[0]-1)\n",
    "    ax.plot(x, y, label=pop, color=color_dict1[pop], lw=lw)\n",
    "    ax.fill_between(x, y-err, y+err, color=color_dict1[pop], alpha=alpha_err, lw=0, zorder=-5)\n",
    "ax.set_xlim(0,180)\n",
    "ax.set_ylim(0,1.1*ax.get_ylim()[1])\n",
    "ax.locator_params('y',nbins=5)\n",
    "ax.set_xlabel(r'Pair angle $\\theta$ (deg)')\n",
    "ax.set_ylabel('Probability density')\n",
    "\n",
    "\n",
    "# Right panel inset: mean speed vs group size.\n",
    "x0,y0,x1,y1 = axs[2].get_position()._points.flatten()\n",
    "x0_,y0_ = x0+0.35*(x1-x0), y0+0.5*(y1-y0)\n",
    "ax_     = fig.add_axes([x0_, y0_, x1-x0_-0.003, y1-y0_-0.01])\n",
    "x,y,err,no,c = zip(*[ (names[k],np.mean(v),np.std(v)/np.sqrt(len(v)-1),len(v),color_dict1[k]) \n",
    "                   for k,v in cos_mean.items() ])\n",
    "x = x[:-1] + ('Surface (dark)',)\n",
    "ax_.bar(x, y, color=c)\n",
    "ax_.errorbar(x, y, yerr=err, fmt='none', color='k', **err_opt2)\n",
    "ax_.set_xticklabels(x, rotation=45, ha='right', y=0.05)\n",
    "ax_.set_yticks([0,1])\n",
    "ax_.set_ylim(0,1.25)\n",
    "ax_.set_ylabel(r'$\\langle\\cos\\,\\theta\\rangle$', labelpad=0)\n",
    "\n",
    "def draw_bracket(txt, x1, x2, y, dx=0, dy=0.05, ax=ax_, **args):\n",
    "    ax.plot([x1+dx,x1+dx,x2-dx,x2-dx], [y-dy,y,y,y-dy], color='k', lw=0.5)\n",
    "    ax.text((x1+x2)/2, y, txt, va='bottom', ha='center', **args)\n",
    "draw_bracket('n.s.', 1, 3, 0.35, dx=-0.2, fontsize=12)\n",
    "# draw_bracket('', 1, 3, 0.4, dx=-0.2)\n",
    "# ax_.text(2, 0.38, 'Cave', va='top', ha='center', fontsize=12)\n",
    "draw_bracket('**', 0, 1.8, 1)\n",
    "ax_.plot([1.8]*2, [1,0.55], color='k', lw=0.5)\n",
    "draw_bracket('*', 2.2, 4, 0.6)\n",
    "ax_.plot([2.2]*2, [0.6,0.55], color='k', lw=0.5)\n",
    "\n",
    "\n",
    "plt.savefig(fpath(\"fig6.png\"), dpi=dpi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical tests for <v(n)> (left panel, inset).\n",
    "\n",
    "# Test normality.\n",
    "print('Shapiro test:')\n",
    "for k,V in cos_mean.items():\n",
    "    print(f'{k}: p = {shapiro(V)[1]}')\n",
    "\n",
    "# Make DataFrame for Tukey test.\n",
    "df = pd.DataFrame([(k,v) for k,V in cos_mean.items() for v in V], columns=['pop','cos_mean'])\n",
    "# print(pairwise_tukeyhsd(df['cos_mean'], df['pop']))\n",
    "\n",
    "cave = ['Pa','Mo','Ti']\n",
    "p = f_oneway(*[V for k,V in cos_mean.items() if k in cave]).pvalue\n",
    "print(f'\\nOne-way ANOVA test among cavefish populations: p = {p}')\n",
    "\n",
    "# Merge cave populations and perform Tukey test.\n",
    "df['pop'] = df['pop'].apply(lambda k: 'cave' if k in cave else k)\n",
    "print()\n",
    "print(pairwise_tukeyhsd(df['cos_mean'], df['pop']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical tests for <cos(theta)> (right panel, inset).\n",
    "\n",
    "# Test normality.\n",
    "print('Shapiro test:')\n",
    "for k,V in cos_mean.items():\n",
    "    print(f'{k}: p = {shapiro(V)[1]}')\n",
    "\n",
    "# Make DataFrame for Tukey test.\n",
    "df = pd.DataFrame([(k,v) for k,V in cos_mean.items() for v in V], columns=['pop','cos_mean'])\n",
    "# print(pairwise_tukeyhsd(df['cos_mean'], df['pop']))\n",
    "\n",
    "cave = ['Pa','Mo','Ti']\n",
    "p = f_oneway(*[V for k,V in cos_mean.items() if k in cave]).pvalue\n",
    "print(f'\\nOne-way ANOVA test among cavefish populations: p = {p}')\n",
    "\n",
    "# Merge cave populations and perform Tukey test.\n",
    "df['pop'] = df['pop'].apply(lambda k: 'cave' if k in cave else k)\n",
    "print()\n",
    "print(pairwise_tukeyhsd(df['cos_mean'], df['pop']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C62_0KhXo3L5"
   },
   "source": [
    "# Figure 7\n",
    "\n",
    "Here, we consider the effect of evasive interactions on time spent in the center of the tank. Experiments show that cave fish spend more time in the center of the tank with increased group size. We compare time in the center across simulations of three variants of a minimal active matter model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vncbqpq8o3MD"
   },
   "source": [
    "Where we consider time in the center of the tank of radius $R$, where the center is defined so that there is an equal area in the center compared to outside of the tank.\n",
    "\\begin{align}\n",
    "A_\\text{center} &= A_\\text{total} /2 \\\\\n",
    "R_\\text{center}^2 &= R^2 /2 \\\\\n",
    "R_\\text{center} &= R / \\sqrt{2} \n",
    "\\end{align}\n",
    "\n",
    "If fish were to spend time uniformly throughout the tank, then the probability of finding the fish in the center and near the walls would be equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridspec = dict(wspace=0.4, bottom=0.15, left=0.01, right=0.99, top=0.97)\n",
    "fig, axs = plt.subplots(ncols=3, nrows=1, figsize=(12,3.8), gridspec_kw=gridspec)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Label each panel.\n",
    "for ax,c in zip(axs,'abc'):\n",
    "    ax.text(0.02, 0.98, c, transform=ax.transAxes, fontsize=24, weight='bold', va='top')\n",
    "\n",
    "    \n",
    "# Left panel: Overlaid screenshots of evasive maneuver.\n",
    "ax = axs[0]\n",
    "evasive_tracks = mpimg.imread(fpath('fig_evasion.png'))\n",
    "ax.imshow(evasive_tracks)\n",
    "ax.axis('off')\n",
    "\n",
    "\n",
    "# Middle panel: Time in center vs group size (experiments).\n",
    "ax  = axs[1]\n",
    "d_expt = trial_store['time-in-center_expt']\n",
    "n_list = [1,2,5,10]\n",
    "for pop in ['Pa','Mo','Ti']:\n",
    "    y   = [ np.mean(d_expt[pop,n]) for n in n_list ]\n",
    "    err = [ np.std(d_expt[pop,n])/np.sqrt(len(d_expt[pop,n])-1) for n in n_list ]\n",
    "    ax.errorbar(n_list, y, yerr=err, label=names[pop], dashes=dashes[pop], \n",
    "                color=color_dict1[pop], alpha=0.8, **err_opt)\n",
    "ax.legend(loc='upper center', **leg_opt)\n",
    "\n",
    "\n",
    "# Right panel: Time in center vs group size (simulations).\n",
    "ax          = axs[2]\n",
    "fic         = trial_store['time-in-center_sims']\n",
    "fic_models  = ['ignore', 'slow', 'avoid', 'combo']\n",
    "fic_markers = ['o', 's', '^', 'p']\n",
    "fic_colors  = ['grey', 'r', 'b', 'magenta']\n",
    "fic_names   = ['Ignore', 'Slowdown', 'Evade', 'Combined']\n",
    "for i,m in enumerate(fic_models):\n",
    "    x,y,err = zip(*[ (k[1], np.mean(f), np.std(f)/np.sqrt(len(f)-1)) for k,f in fic.items() if k[0]==m])\n",
    "#     ax.errorbar(x, y, yerr=err, label=fic_names[i], color=fic_colors[i], marker=fic_markers[i], ms=7, **err_opt)\n",
    "    ax.plot(x, y, label=fic_names[i], color=fic_colors[i], alpha=0.8, marker=fic_markers[i], ms=7)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(0.1, 1), **leg_opt)\n",
    "\n",
    "\n",
    "# Common settings for middle and right panels.\n",
    "for ax in axs[1:]:\n",
    "    ax.set_xlabel('Group size')\n",
    "    ax.set_ylabel('Fraction of time in center')\n",
    "    ax.set_xlim(0,12.5)\n",
    "    ax.set_ylim(0,0.55)\n",
    "    ax.set_xticks([1,2,5,10])\n",
    "    ax.set_yticks([0,0.2,0.4])\n",
    "#     ax.legend(loc='upper left', bbox_to_anchor=(0.17,1), **leg_opt)\n",
    "\n",
    "\n",
    "plt.savefig(fpath(\"fig7.png\"), dpi=dpi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "CEPq_SBlo3Id",
    "okELRgbz_j_o",
    "h5zjZYeZo3Ip",
    "OUu-pxIqo3I5",
    "s-6RIbnbo3JK",
    "L_cL6nPXo3Jd",
    "__234yG3o3KL",
    "zHwOwPtKo3KV",
    "BKFnj8PUo3K1",
    "C62_0KhXo3L5"
   ],
   "name": "Figures.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python (main)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
