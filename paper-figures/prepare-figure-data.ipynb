{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/disk2/adult_schooling/trilab-tracker/paper-figures'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, re, warnings, logging, pickle, bz2\n",
    "from os.path import join\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "sys.path.append('..')\n",
    "import trilabtracker as tt\n",
    "\n",
    "from importlib import reload\n",
    "for m in tt.__all__:\n",
    "    eval(f'reload(tt.{m})')\n",
    "reload(tt)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 6,4\n",
    "dpi = 150\n",
    "\n",
    "R_cm         = 55.5\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare trial data.\n",
    "\n",
    "Prepare a dictionary of trials to analyze with basic info for each (path to trial file, population, age, number of individuals, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>n_ind</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mo</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pa</th>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sf</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ti</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "n_ind  1   2   5   10\n",
       "pop                  \n",
       "mo      4   4   4   4\n",
       "pa     20   9  10   4\n",
       "sf     20  10  12  10\n",
       "ti      4   4   4   3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load list of trial names to use in the analysis.\n",
    "valid_trials = open('../settings/adult-trials-to-analyze.txt').readlines()\n",
    "valid_trials = [ fn.strip() for fn in valid_trials ]\n",
    "\n",
    "# Extract trial metadata from the trial's filename.\n",
    "def parse_trial_file(trial_file, etho=False):\n",
    "#     if etho:\n",
    "#         trial_dir  = None\n",
    "#         trial_name = os.path.basename(trial_file)\n",
    "#         trial_name = trial_name.split('-')[1]\n",
    "#     else:\n",
    "    trial_dir  = os.path.dirname(trial_file)\n",
    "    trial_name = os.path.basename(trial_dir)\n",
    "    _,pop,n    = trial_name.lower().split('_')[:3]\n",
    "    n_ind      = int(n[1:])\n",
    "    if 'dark' in trial_name.lower():\n",
    "        pop = pop+'-dark'\n",
    "        # Skip dark trials until I implement one-sided background subtraction.\n",
    "        return None\n",
    "    \n",
    "    if not trial_name in valid_trials:\n",
    "        return None\n",
    "    trial      = { k:v for k,v in locals().items() if k in ['trial_file', \n",
    "                              'trial_dir', 'trial_name', 'pop', 'n_ind'] }\n",
    "    trial['R_cm'] = R_cm\n",
    "    return trial\n",
    "\n",
    "# trilabtracker only for now\n",
    "def load_trial(trial_file, **args):\n",
    "    trial = parse_trial_file(trial_file)\n",
    "    return tt.preprocess_trial(trial, **args)\n",
    "    ''' !!!! '''\n",
    "    # [?] Replace orientations (data[:,:,2]) with displacement-based ones.\n",
    "    # [!] Handle overlaps.\n",
    "    ''' !!!! '''    \n",
    "\n",
    "# Select a set of trials to analyze.\n",
    "trial_files = sorted(glob('../tracking_output/*/trial.pik'))\n",
    "# print(trial_files)\n",
    "\n",
    "# Count trials of each type.\n",
    "trials = [ parse_trial_file(f) for f in trial_files ]\n",
    "trials = pd.DataFrame(trials, index=trial_files)\n",
    "grouped_trials = trials.groupby(['pop','n_ind'])\n",
    "count  = pd.DataFrame(grouped_trials['trial_dir'].count().rename('count'))\n",
    "count = count.unstack(1)\n",
    "count.columns = count.columns.droplevel()\n",
    "count[pd.isna(count)] = 0\n",
    "count = count.astype(int)\n",
    "display(count)\n",
    "\n",
    "def matching_trials(pop=None, n_ind=None, df=trials):\n",
    "    I = pd.Series(data=True, index=df.index)\n",
    "    if not pop is None:\n",
    "        I = I & (df['pop']==pop)\n",
    "    if not n_ind is None:\n",
    "        I = I & (df['n_ind']==n_ind)\n",
    "    return df[I].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_ranges0 = { 'v':[0,100], 'v_ang':[-30,30], 't':[600,1800] }\n",
    "cut_ranges1 = { 'v':[1,100], 'v_ang':[-30,30], 't':[600,1800] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_data = dict(\n",
    "#     bins_dWall    = R_cm - np.sqrt(np.linspace(R_cm**2,0,20)), \n",
    "# #     bins_v        = np.linspace(*cut_ranges['v'],20), \n",
    "# #     bins_vAng     = np.linspace(*cut_ranges['v_ang'],20), \n",
    "# #     bins_pairDist = np.linspace(0,2*R_cm,60), \n",
    "# #     bins_pairAng  = np.linspace(0,np.pi,30), \n",
    "#     )\n",
    "# globals().update(fig_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 40.44it/s]\n"
     ]
    }
   ],
   "source": [
    "fig1        = { k:defaultdict(list) for k in ['density', 'nematic', 'median'] }\n",
    "bins        = R_cm - np.sqrt(np.linspace(R_cm**2,0,20))\n",
    "bin_centers = (bins[1:]+bins[:-1])\n",
    "for trial_file in tqdm(matching_trials(n_ind=1)):\n",
    "    trial = load_trial(trial_file, load_timestamps=False, cut_ranges=cut_ranges0)\n",
    "    globals().update(trial)\n",
    "    # Area density and nematic OP vs distance to the wall.\n",
    "    vals       = d_wall.flatten()\n",
    "    median     = np.nanmedian(vals)\n",
    "    density,_  = np.histogram(vals, bins=bins)\n",
    "    area       = np.pi*(R_cm-bins[:-1])**2 - np.pi*(R_cm-bins[1:])**2\n",
    "    density    = density/np.sum(density)/area\n",
    "    nematic    = []\n",
    "    for i in range(len(bins)-1):\n",
    "        I = (vals>=bins[i])&(vals<bins[i+1])\n",
    "        thetaP = np.arctan2(pos[I,0,1],pos[I,0,0]) # position angle (polar angle)\n",
    "        thetaV = np.arctan2(vel[I,0,1],vel[I,0,0]) # velocity angle\n",
    "        thetaW = thetaV-thetaP # velocity angle with respect to closest wall\n",
    "        thetaW = thetaW - 2*np.pi*np.rint(thetaW/(2*np.pi)) # between -pi and pi\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            nematic.append(np.nanmean(np.cos(2*thetaW)))\n",
    "    fig1['density'][pop].append(density)\n",
    "    fig1['nematic'][pop].append(nematic)\n",
    "    fig1['median'][pop].append(median)\n",
    "#     break\n",
    "for k1,v1 in fig1.items():\n",
    "    for k2,v2 in v1.items():\n",
    "        fig1[k1][k2] = np.array(v2)\n",
    "fig1['bin_centers'] = bin_centers\n",
    "\n",
    "# pickle.dump( dict(fig1=fig1), open('figure-data.pik','wb') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( dict(fig1=fig1), open('figure-data.pik','wb') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:06<00:00, 19.79it/s]\n"
     ]
    }
   ],
   "source": [
    "fig2        = { k:defaultdict(list) for k in ['speed_distribution', 'inactive_fraction'] }\n",
    "bins        = np.linspace(0,100,101)\n",
    "bin_centers = (bins[1:]+bins[:-1])/2\n",
    "v_inactive  = 1\n",
    "for trial_file in tqdm(trials.index):\n",
    "    trial = load_trial(trial_file, load_timestamps=False, cut_ranges=cut_ranges0)\n",
    "    globals().update(trial)\n",
    "    if pop=='sf':\n",
    "        h,_  = np.histogram(v.flatten(), bins=bins, density=True)\n",
    "        fig2['speed_distribution'][pop,n_ind].append(h)\n",
    "    f = np.count_nonzero(v>v_inactive)/np.count_nonzero(np.isfinite(v))\n",
    "    fig2['inactive_fraction'][pop,n_ind].append(f)\n",
    "for k,v in fig2['speed_distribution'].items():\n",
    "    fig2['speed_distribution'][k] = np.array(v)\n",
    "fig2['speed_distribution']['bin_centers'] = bin_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( dict(fig1=fig1, fig2=fig2), open('figure-data.pik','wb') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "okELRgbz_j_o"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ### Analyze trials.\n",
    "\n",
    "# traj_data = {}\n",
    "# stat_data = dict(\n",
    "#     bins_dWall    = np.linspace(0,R_cm,100), \n",
    "#     bins_v        = np.linspace(*cut_ranges['v'],100), \n",
    "#     bins_vAng     = np.linspace(*cut_ranges['v_ang'],100), \n",
    "#     bins_pairDist = np.linspace(0,2*R_cm,60), \n",
    "#     bins_pairAng  = np.linspace(0,np.pi,30), \n",
    "#     )\n",
    "# globals().update(stat_data)\n",
    "# results = {}\n",
    "\n",
    "# for trial_file in tqdm(trials.index):\n",
    "    \n",
    "#     trial = load_trial(trial_file, load_timestamps=False, cut_ranges=cut_ranges)\n",
    "#     globals().update(trial)\n",
    "    \n",
    "#     # [?] Replace orientations (data[:,:,2]) with displacement-based ones.\n",
    "    \n",
    "#     # Save trajectories.\n",
    "#     traj_data[trial_name] = pos[:,:,:2]\n",
    "    \n",
    "#     # [!] Handle overlaps.\n",
    "    \n",
    "#     # Distribution of distance to the wall.\n",
    "#     bins, vals = bins_dWall, d_wall.flatten()\n",
    "#     hist_dWall = np.histogram(vals[~np.isnan(vals)], bins=bins)\n",
    "    \n",
    "#     # Speed distribution.\n",
    "#     bins, vals = bins_v, v.flatten()\n",
    "#     hist_v = np.histogram(vals[~np.isnan(vals)], bins=bins)\n",
    "    \n",
    "#     # Angular speed distribution.\n",
    "#     bins, vals = bins_vAng, vel[:,:,2].flatten()\n",
    "#     hist_vAng = np.histogram(vals[~np.isnan(vals)], bins=bins)\n",
    "    \n",
    "#     # Joint distribution of pair distance and pair angle,\n",
    "#     if n_ind>1:\n",
    "#         bins_d  = bins_pairDist\n",
    "#         bins_a  = bins_pairAng\n",
    "#         J1,J2 = np.triu_indices(n_ind,1)\n",
    "#         d     = np.hypot(pos[:,J1,0]-pos[:,J2,0],pos[:,J1,1]-pos[:,J2,1]).flatten()\n",
    "#         a     = (pos[:,J1,2]-pos[:,J2,2]).flatten()\n",
    "#         a     = a - 2*np.pi*np.rint(a/(2*np.pi))\n",
    "#         I     = np.logical_not(np.logical_or(np.isnan(d),np.isnan(a)))\n",
    "#         d     = d[I]\n",
    "#         a     = np.absolute(a[I])\n",
    "#         # 2D histogram of pairwise distance and angle.\n",
    "#         hist_distAng = np.histogram2d(d, a, bins=(bins_d,bins_a), density=True)\n",
    "#         # Pairwise polar alignment parameter vs pair distance.\n",
    "#         K = np.digitize(d,bins_d)\n",
    "#         with warnings.catch_warnings():\n",
    "#             warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "#             p = np.array([ np.nanmean(np.cos(a[K==i])) for i in range(len(bins_d)+1) ])\n",
    "#         polar = p[1:-1],bins_d\n",
    "#     else:\n",
    "#         hist_distAng,polar = None,None\n",
    "\n",
    "#     # Save output.\n",
    "#     results[trial_file] = { k:v for k,v in locals().items() if k in \n",
    "#                                [ 'valid_fraction', 'hist_area', 'hist_aspect', 'hist_dWall', \n",
    "#                                  'hist_v', 'hist_vAng', 'hist_distAng', 'polar' ] }\n",
    "# #     break\n",
    "\n",
    "# stat_data['results'] = results\n",
    "# pickle.dump(stat_data, open(join(cut_dir,'stats.pik'), 'wb'))\n",
    "# pickle.dump(traj_data, open(join(cut_dir,'trajectories.pik'), 'wb'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "CEPq_SBlo3Id",
    "okELRgbz_j_o",
    "h5zjZYeZo3Ip",
    "OUu-pxIqo3I5",
    "s-6RIbnbo3JK",
    "L_cL6nPXo3Jd",
    "__234yG3o3KL",
    "zHwOwPtKo3KV",
    "BKFnj8PUo3K1",
    "C62_0KhXo3L5"
   ],
   "name": "Figures.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python (main)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
