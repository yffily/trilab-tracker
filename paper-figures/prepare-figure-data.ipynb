{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, warnings, logging, pickle, bz2\n",
    "from os.path import join\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_list_like\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "sys.path.append('..')\n",
    "import trilabtracker as tt\n",
    "\n",
    "from importlib import reload\n",
    "for m in tt.__all__:\n",
    "    eval(f'reload(tt.{m})')\n",
    "reload(tt)\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare trial data.\n",
    "\n",
    "Define notebook-wide quantities (tank radius, cut ranges). Prepare a dictionary of trials to analyze with basic info about each (path to trial file, population, number of individuals, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list of trial names to use in the analysis.\n",
    "valid_trials = open('../settings/adult-trials-to-analyze.txt').readlines()\n",
    "valid_trials = [ fn.strip() for fn in valid_trials ]\n",
    "\n",
    "# Tank radius.\n",
    "R_cm        = 55.5\n",
    "\n",
    "# Extract trial metadata from the trial's filename.\n",
    "def parse_trial_file(trial_file, etho=False):\n",
    "#     if etho:\n",
    "#         trial_dir  = None\n",
    "#         trial_name = os.path.basename(trial_file)\n",
    "#         trial_name = trial_name.split('-')[1]\n",
    "#     else:\n",
    "    trial_dir  = os.path.dirname(trial_file)\n",
    "    trial_name = os.path.basename(trial_dir)\n",
    "    _,pop,n    = trial_name.lower().split('_')[:3]\n",
    "    n_ind      = int(n[1:])\n",
    "    if 'dark' in trial_name.lower():\n",
    "        pop = pop+'-dark'\n",
    "        # Skip dark trials until I implement one-sided background subtraction.\n",
    "#         return {}\n",
    "    if not trial_name in valid_trials:\n",
    "        return {}\n",
    "    trial      = { k:v for k,v in locals().items() if k in ['trial_file', \n",
    "                              'trial_dir', 'trial_name', 'pop', 'n_ind'] }\n",
    "    trial['R_cm'] = R_cm\n",
    "    return trial\n",
    "\n",
    "# trilabtracker only for now\n",
    "def load_trial(trial_file, **args):\n",
    "    trial = parse_trial_file(trial_file)\n",
    "    return tt.preprocess_trial(trial, load_timestamps=False, orientation='body', \n",
    "                               wall_distance=True, n_smooth=3, buffer_frames=0, \n",
    "                               **args)\n",
    "    ''' !!!! '''\n",
    "    # [done] Replace orientations (data[:,:,2]) with displacement-based ones.\n",
    "    # [!] Handle overlaps.\n",
    "    ''' !!!! '''    \n",
    "\n",
    "# Select a set of trials to analyze.\n",
    "trial_files = sorted(glob('../tracking_output/*/trial.pik'))\n",
    "# print(trial_files)\n",
    "\n",
    "# Count trials of each type.\n",
    "trials = [ parse_trial_file(f) for f in trial_files ]\n",
    "trials = pd.DataFrame(trials, index=trial_files)\n",
    "trials = trials.dropna()\n",
    "grouped_trials = trials.groupby(['pop','n_ind'])\n",
    "count  = pd.DataFrame(grouped_trials['trial_dir'].count().rename('count'))\n",
    "count = count.unstack(1)\n",
    "count.columns = count.columns.droplevel().astype(int)\n",
    "count[pd.isna(count)] = 0\n",
    "count = count.astype(int)\n",
    "display(count)\n",
    "\n",
    "# Return the list of trials matching some condition.\n",
    "# For column name from the trial dataframe is a valid argument.\n",
    "# Provide a value or list of values to match.\n",
    "# Example: matching_trials(pop=['mo','ti'], n_ind=5)\n",
    "def matching_trials(df=trials, **args):\n",
    "    I = pd.Series(data=True, index=df.index)\n",
    "    for k,v in args.items():\n",
    "        if not v is None:\n",
    "            if is_list_like(v):\n",
    "                I = I & df[k].isin(v)\n",
    "            else:\n",
    "                I = I & (df[k]==v)\n",
    "    return df[I].index.tolist()\n",
    "\n",
    "# Need two distinct cuts: one with inactive fish and one without.\n",
    "v_inactive  = 3\n",
    "cut_ranges0 = { 'v':[0,100], 'v_ang':[-30,30], 't':[600,1800] }\n",
    "cut_ranges1 = { 'v':[v_inactive,100], 'v_ang':[-30,30], 't':[600,1800] }\n",
    "\n",
    "# Inactivity filter.\n",
    "def is_active(v, v_inactive=v_inactive, buffer_frames=0):\n",
    "    I = v>v_inactive\n",
    "    for j in range(buffer_frames):\n",
    "        # Grow inactive region by one frame in each direction.\n",
    "        I[1:-1] = I[0:-2] & I[1:-1] & I[2:]\n",
    "    return I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1\n",
    "\n",
    "Distance to the wall and nematic order parameter w.r.t. the wall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_data    = { k:defaultdict(list) for k in ['density', 'nematic', 'median'] }\n",
    "cut_ranges  = cut_ranges0\n",
    "bins        = R_cm - np.sqrt(np.linspace(R_cm**2,0,20))\n",
    "for trial_file in tqdm(matching_trials(n_ind=1)):\n",
    "    trial = load_trial(trial_file, cut_ranges=cut_ranges)\n",
    "    globals().update(trial)\n",
    "    # Area density and nematic OP vs distance to the wall.\n",
    "    vals       = d_wall.flatten()\n",
    "    median     = np.nanmedian(vals)\n",
    "    density,_  = np.histogram(vals, bins=bins)\n",
    "    area       = np.pi*(R_cm-bins[:-1])**2 - np.pi*(R_cm-bins[1:])**2\n",
    "    density    = density/np.sum(density)/area\n",
    "    nematic    = []\n",
    "    for i in range(len(bins)-1):\n",
    "        I = (vals>=bins[i])&(vals<bins[i+1])\n",
    "        thetaP = np.arctan2(pos[I,0,1],pos[I,0,0]) # position angle (polar angle)\n",
    "#         thetaO = np.arctan2(vel[I,0,1],vel[I,0,0]) # velocity angle\n",
    "        thetaO = pos[I,0,2] # body orientation angle\n",
    "        thetaW = thetaO-thetaP # velocity angle with respect to closest wall\n",
    "        thetaW = thetaW - 2*np.pi*np.rint(thetaW/(2*np.pi)) # between -pi and pi\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            nematic.append(np.nanmean(np.cos(2*thetaW)))\n",
    "    fig_data['density'][pop].append(density)\n",
    "    fig_data['nematic'][pop].append(nematic)\n",
    "    fig_data['median'][pop].append(median)\n",
    "#     break\n",
    "for k1,v1 in fig_data.items():\n",
    "    for k2,v2 in v1.items():\n",
    "        fig_data[k1][k2] = np.array(v2)\n",
    "fig_data['bin_centers'] = (bins[1:]+bins[:-1])/2\n",
    "\n",
    "pickle.dump( fig_data, open('data/figure1-data.pik','wb') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2\n",
    "\n",
    "Fraction of the time active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_data    = { k:defaultdict(list) for k in ['speed_distribution', 'inactive_fraction'] }\n",
    "cut_ranges  = cut_ranges0\n",
    "bins        = np.linspace(*cut_ranges['v'],101)\n",
    "for trial_file in tqdm(trials.index):\n",
    "    trial = load_trial(trial_file, cut_ranges=cut_ranges)\n",
    "    globals().update(trial)\n",
    "    if pop=='sf':\n",
    "        h,_  = np.histogram(v.flatten(), bins=bins, density=True)\n",
    "        fig_data['speed_distribution'][pop,n_ind].append(h)\n",
    "    f = np.count_nonzero(is_active(v))/np.count_nonzero(np.isfinite(v))\n",
    "    fig_data['inactive_fraction'][pop,n_ind].append(f)\n",
    "for k,v in fig_data['speed_distribution'].items():\n",
    "    fig_data['speed_distribution'][k] = np.array(v)\n",
    "fig_data['speed_distribution']['bin_centers'] = (bins[1:]+bins[:-1])/2\n",
    "\n",
    "pickle.dump( fig_data, open('data/figure2-data.pik','wb') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures 3 & S3\n",
    "\n",
    "Distribution of speed when active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "for m in tt.__all__:\n",
    "    eval(f'reload(tt.{m})')\n",
    "reload(tt)\n",
    "\n",
    "fig_data    = { k:defaultdict(list) for k in ['speed_distribution', 'mean_speed'] }\n",
    "cut_ranges  = cut_ranges1\n",
    "bins        = np.linspace(*cut_ranges['v'],101)\n",
    "for trial_file in tqdm(trials.index):\n",
    "    trial = load_trial(trial_file, cut_ranges=cut_ranges)\n",
    "    globals().update(trial)\n",
    "#     h,_   = np.histogram(v.flatten(), bins=bins, density=True)\n",
    "    h,_   = np.histogram(v[is_active(v)].flatten(), bins=bins, density=True)\n",
    "    fig_data['speed_distribution'][pop,n_ind].append(h)\n",
    "    fig_data['mean_speed'][pop,n_ind].append(np.nanmean(v))\n",
    "for k,v in fig_data['speed_distribution'].items():\n",
    "    fig_data['speed_distribution'][k] = np.array(v)\n",
    "fig_data['speed_distribution']['bin_centers'] = (bins[1:]+bins[:-1])/2\n",
    "\n",
    "pickle.dump( fig_data, open('data/figure3-data.pik','wb') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures 4 & S4\n",
    "\n",
    "Distribution of angular speed when active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "for m in tt.__all__:\n",
    "    eval(f'reload(tt.{m})')\n",
    "reload(tt)\n",
    "\n",
    "fig_data    = { k:defaultdict(list) for k in ['angSpeed_distribution'] }\n",
    "cut_ranges  = cut_ranges1\n",
    "# bins        = np.linspace(0,cut_ranges['v_ang'][1],61)\n",
    "# bins        = np.concatenate([np.linspace(0,2,20)[:-1],\n",
    "#                               np.linspace(2,cut_ranges['v_ang'][1],40)])\n",
    "bins        = np.linspace(0,np.sqrt(cut_ranges['v_ang'][1]),61)**2\n",
    "for trial_file in tqdm(trials.index):\n",
    "    trial = load_trial(trial_file, cut_ranges=cut_ranges)\n",
    "    globals().update(trial)\n",
    "#     vals  = np.absolute(vel[:,:,2])\n",
    "    vals  = np.absolute(vel[is_active(v),2])\n",
    "    h,_   = np.histogram(vals.flatten(), bins=bins, density=True)\n",
    "    fig_data['angSpeed_distribution'][pop,n_ind].append(h)\n",
    "for k,v in fig_data['angSpeed_distribution'].items():\n",
    "    fig_data['angSpeed_distribution'][k] = np.array(v)\n",
    "fig_data['angSpeed_distribution']['bin_centers'] = (bins[1:]+bins[:-1])/2\n",
    "\n",
    "pickle.dump( fig_data, open('data/figure4-data.pik','wb') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures 5 & S5\n",
    "\n",
    "Joint distribution of pair distance and pair angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "for m in tt.__all__:\n",
    "    eval(f'reload(tt.{m})')\n",
    "reload(tt)\n",
    "\n",
    "# fig_data    = { k:defaultdict(list) for k in ['distAng_heatmap','cos_mean'] }\n",
    "fig_data    = defaultdict(lambda: defaultdict(list))\n",
    "cut_ranges  = cut_ranges0\n",
    "bins_d      = np.arange(0,2*R_cm+1,1)\n",
    "bins_a      = np.linspace(0,180,112)\n",
    "d0          = 10 # distance threshold for close-range\n",
    "for trial_file in tqdm(trials.index):\n",
    "    if trials.loc[trial_file,'n_ind'] == 1:\n",
    "        continue\n",
    "    trial = load_trial(trial_file, cut_ranges=cut_ranges)\n",
    "    globals().update(trial)\n",
    "    \n",
    "    J1,J2 = np.triu_indices(n_ind,1)\n",
    "    d     = np.hypot(pos[:,J1,0]-pos[:,J2,0],pos[:,J1,1]-pos[:,J2,1]).flatten()\n",
    "    a     = (pos[:,J1,2]-pos[:,J2,2]).flatten()\n",
    "    a     = a - 2*np.pi*np.rint(a/(2*np.pi))\n",
    "    I     = np.isfinite(d) & np.isfinite(a) & (d>1e-6)\n",
    "    d     = d[I]\n",
    "    a     = np.absolute(a[I])*180/np.pi\n",
    "    # 2D histogram of pairwise distance and angle.\n",
    "    distAng_heatmap = np.histogram2d(d, a, bins=(bins_d,bins_a), density=True)[0]\n",
    "    # Distribution and mean cosine of angle at close range.\n",
    "    a_    = np.absolute(a[d<d0])\n",
    "    ang_distribution = np.histogram(a_, bins=bins_a, density=True)[0]\n",
    "    polar = np.nanmean(np.cos(a_*np.pi/180))\n",
    "    \n",
    "#     # Pairwise polar alignment parameter vs pair distance.\n",
    "#     K = np.digitize(d,bins_d)\n",
    "#     with warnings.catch_warnings():\n",
    "#         warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "#         p = np.array([ np.nanmean(np.cos(a[K==i])) for i in range(len(bins_d)+1) ])\n",
    "#     polar = p[1:-1]\n",
    "    \n",
    "    fig_data['distAng_heatmap'][pop,n_ind].append(distAng_heatmap)\n",
    "    fig_data['ang_distribution'][pop,n_ind].append(ang_distribution)\n",
    "    fig_data['polar'][pop,n_ind].append(polar)\n",
    "\n",
    "for k,v in fig_data['distAng_heatmap'].items():\n",
    "    fig_data['distAng_heatmap'][k] = np.mean(v, axis=0)\n",
    "for q in ['ang_distribution','polar']:\n",
    "    for k,v in fig_data[q].items():\n",
    "        fig_data[q][k] = np.array(v)\n",
    "fig_data['bins_d'] = bins_d\n",
    "fig_data['bins_a'] = bins_a\n",
    "fig_data           = dict(fig_data)\n",
    "\n",
    "pickle.dump( fig_data, open('data/figure5-data.pik','wb') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "CEPq_SBlo3Id",
    "okELRgbz_j_o",
    "h5zjZYeZo3Ip",
    "OUu-pxIqo3I5",
    "s-6RIbnbo3JK",
    "L_cL6nPXo3Jd",
    "__234yG3o3KL",
    "zHwOwPtKo3KV",
    "BKFnj8PUo3K1",
    "C62_0KhXo3L5"
   ],
   "name": "Figures.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python (main)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
