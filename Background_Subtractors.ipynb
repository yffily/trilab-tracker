{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import platform, os, sys, datetime, re\n",
    "import multiprocessing\n",
    "from os.path import join\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# sys.path.append(join(root_dir,'cvtracer'))\n",
    "import cvt\n",
    "from cvt.TrAQ.Trial import Trial\n",
    "from cvt.TrAQ.Tank import Tank\n",
    "from cvt.TrAQ.CVTracer import CVTracer, create_named_window, wait_on_named_window\n",
    "from cvt.utils import *\n",
    "\n",
    "default_settings = dict(\n",
    "    t_start        = 0,     # Time at which to start tracking, in seconds.\n",
    "    t_end          = -1,    # Time at which to end tracking, in seconds.\n",
    "    \n",
    "    # Background subtraction (for naive background subtraction only).\n",
    "    bkg_frame_skip = 100,   # Using every frame of the video to compute the background takes a while.\n",
    "                            # Instead we only use one frame in bkg_frame_skip.\n",
    "    bkg_sub_amp    = 4,     # Contrast amplification factor applied after background subtraction.\n",
    "    \n",
    "    # Contour detection.\n",
    "    n_pixel_blur   =  7,    # square-root of n-pixels for threshold blurring\n",
    "    block_size     = 15,    # contour block size\n",
    "    thresh_offset  = 15,    # threshold offset for contour-finding\n",
    "    min_area       = 25,    # minimum area for threhold detection\n",
    "    max_area       = 60,    # maximum area for threhold detection\n",
    "    RGB            = False, # track in color, false does greyscale\n",
    "    online_viewer  = False, # Toggle live preview of tracking.\n",
    "\n",
    "    # What information to draw on the tracking output video.\n",
    "    video_output_options = dict(tank=True, repeat_contours=False, all_contours=True, \n",
    "                                contour_color=(0,200,255), contour_thickness=1, \n",
    "                                points=False, directors=True, timestamp=True)\n",
    "    )\n",
    "\n",
    "settings_list = list(default_settings.keys()) + \\\n",
    "                ['input_file', 'tracking_dir', 'output_dir', 'trial_file',  \n",
    "                 'new_input_file', 'bkg_file', 'tank_file', 'settings_file', \n",
    "                 'tank_radius', 'ext', 'filename', 'pop', 'age', 'group', 'Nfish', \n",
    "                 'Nframes', 'fps', 'fourcc', 'width', 'height']\n",
    "\n",
    "def create_settings_(input_file, tracking_dir, settings):\n",
    "    \n",
    "    globals().update(settings)\n",
    "    tank_diameter_vs_age = { 7:9.6, 14:10.4, 21:12.8, 28:17.7, 42:33.8 }\n",
    "    \n",
    "    ''' Extract trial info from the filename and the video itself. '''\n",
    "\n",
    "    filename,ext = os.path.splitext(os.path.basename(input_file))\n",
    "    pop,_,age,group,Nfish = filename.split('_')[:5]\n",
    "    Nfish    = int(re.findall('\\d+',Nfish)[0])\n",
    "    age      = int(age[:-3])\n",
    "    tank_radius = tank_diameter_vs_age[age]/2\n",
    "\n",
    "    cap      = cv2.VideoCapture(input_file)\n",
    "    cap.read()\n",
    "    Nframes  = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps      = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    fourcc   = int(cap.get(cv2.CAP_PROP_FOURCC))\n",
    "    width    = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height   = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    cap.release()\n",
    "    \n",
    "    ''' Define and create necessary folders/files/links. '''\n",
    "    \n",
    "    output_dir = join(tracking_dir,filename)\n",
    "\n",
    "    new_input_file = input_file\n",
    "    if not 'windows' in platform.system().lower():\n",
    "        new_input_file = join(output_dir,'raw'+ext)\n",
    "    \n",
    "    settings_file = join(output_dir,'tracking_settings.txt')\n",
    "    trial_file    = join(output_dir,'trial.pik')\n",
    "    tank_file     = join(output_dir,'tank.pik')\n",
    "    bkg_file      = join(output_dir,f'background-{bkg_frame_skip}.npz')\n",
    "    \n",
    "    for k,v in locals().items():\n",
    "        if k not in ['cap','settings','tank_diameter_vs_age','_']:\n",
    "            settings[k] = v\n",
    "        \n",
    "    return settings\n",
    "\n",
    "\n",
    "def create_directories(settings):\n",
    "    for k in 'tracking_dir','output_dir','input_file','new_input_file':\n",
    "        globals()[k] = settings[k]\n",
    "    if not os.path.exists(tracking_dir):\n",
    "        os.mkdir(tracking_dir)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    if not 'windows' in platform.system().lower():\n",
    "        if not os.path.exists(new_input_file):\n",
    "            os.symlink(os.path.relpath(input_file,output_dir),new_input_file)\n",
    "    return\n",
    "\n",
    "\n",
    "def save_settings(settings):\n",
    "    with open(settings['settings_file'],'w') as fh:\n",
    "        for k,v in settings.items():\n",
    "            print(f'{k} = {v}',file=fh)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locate input/output and allocate CPU's\n",
    "\n",
    "`tracking_dir` sets the top-level output directory. The output of tracking each video will go in `tracking_dir`, in a subdirectory named after the input video file.  \n",
    "\n",
    "`n_threads` controls the number of tracking tasks to execute simulataneously. `n_threads = None` defaults to the number of CPU's on the machine running the notebook.\n",
    "\n",
    "`input_files` set the list of video files to perform tracking on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./test/input/Pa_Fri_7dpf_GroupA_n5_2020-06-05-083453-0000_60-70.avi',\n",
       " './test/input/Pa_Fri_7dpf_GroupA_n2b_2020-06-05-103456-0000_60-120.avi',\n",
       " './test/input/Pa_Fri_7dpf_GroupA_n5_2020-06-05-083453-0000_60-120.avi',\n",
       " './test/input/Pa_Fri_7dpf_GroupA_n2b_2020-06-05-103456-0000_60-70.avi']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tracking_dir = '../tracking/full' # use this one to track full videos\n",
    "# tracking_dir = '../tracking/partial' # use this one to track small excerpts\n",
    "tracking_dir = './test/output' # use this one to track small excerpts\n",
    "\n",
    "def create_settings(input_file,tracking_dir=tracking_dir,settings=default_settings):\n",
    "    return create_settings_(input_file,tracking_dir,settings)\n",
    "\n",
    "n_threads = None\n",
    "\n",
    "# input_files = sorted(glob('../raw_videos/*.avi'))\n",
    "# input_files = sorted(glob('../raw_videos/*_*_7dpf_*.avi'))\n",
    "\n",
    "# input_files = []\n",
    "# for f in sorted(glob('../raw_videos/*.avi')):\n",
    "#     print(f)\n",
    "#     settings = create_settings(f)\n",
    "#     if not os.path.exists(settings['trial_file']):\n",
    "#         input_files.append(f)\n",
    "# display(input_files)\n",
    "\n",
    "input_files = glob('./test/input/*.avi')\n",
    "display(input_files)\n",
    "\n",
    "input_files = [ input_files[0] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locate the tanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test/input/Pa_Fri_7dpf_GroupA_n5_2020-06-05-083453-0000_60-70.avi\n",
      "\n",
      "        Tank object loaded from ./test/output/Pa_Fri_7dpf_GroupA_n5_2020-06-05-083453-0000_60-70/tank.pik \n"
     ]
    }
   ],
   "source": [
    "for input_file in input_files:\n",
    "    print(input_file)\n",
    "    settings = create_settings(input_file)\n",
    "    create_directories(settings)\n",
    "    globals().update(settings)\n",
    "    tank = Tank(r_cm=tank_radius)\n",
    "    tank.load_or_locate_and_save(tank_file,input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the background\n",
    "\n",
    "### Using a naive average\n",
    "\n",
    "Compute the background by averaging frames over the entire video. Save it as `background.npy` in the output directory. Use the pre-existing file if there is one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test/input/Pa_Fri_7dpf_GroupA_n2b_2020-06-05-103456-0000_60-120.avi\n",
      "Using every {bkg_frame_skip}th frame.\n",
      "0:00:03.045343\n"
     ]
    }
   ],
   "source": [
    "def subtract_background(frame,bkg,bkg_sub_amp):\n",
    "    return 255-np.minimum(255,bkg_sub_amp*np.absolute(frame-bkg)).astype(np.uint8)    \n",
    "\n",
    "\n",
    "def compute_background(settings):\n",
    "    \n",
    "    globals().update(settings)\n",
    "    \n",
    "    if os.path.exists(bkg_file):\n",
    "        bkg  = np.load(bkg_file)['bkg']\n",
    "    else:\n",
    "        t0    = datetime.datetime.now()\n",
    "        cap   = cv2.VideoCapture(new_input_file)\n",
    "        _,frame = cap.read()\n",
    "        bkg   = np.zeros(frame.shape,dtype=float)\n",
    "        count = 0\n",
    "        # If bkg_frame_skip is small (<10) it may be faster to use\n",
    "        # cap.grab instead of cap.set.\n",
    "        for n in range(0,Nframes,bkg_frame_skip):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES,n)\n",
    "            ret,frame = cap.read()\n",
    "            bkg      += frame\n",
    "            count    += 1\n",
    "        bkg   = bkg / count\n",
    "        np.savez_compressed(bkg_file,bkg=bkg)\n",
    "        print(input_file)\n",
    "        print('Using every {bkg_frame_skip}th frame.')\n",
    "        print(datetime.datetime.now()-t0)\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    # Show the background.\n",
    "    cv2.imwrite(join(output_dir,'background.png'),bkg)\n",
    "    \n",
    "    return\n",
    "\n",
    "#---------------------------------------------------\n",
    "\n",
    "# Single thread version.\n",
    "for f in input_files:\n",
    "    settings = create_settings(f)\n",
    "    compute_background(settings)\n",
    "\n",
    "#----\n",
    "\n",
    "# # Multithread version.\n",
    "# with multiprocessing.Pool(n_threads) as pool:\n",
    "#     pool.map(compute_background,[create_settings(f) for f in input_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using various methods from openCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals().update(settings)\n",
    "\n",
    "from cv2 import createBackgroundSubtractorKNN, createBackgroundSubtractorMOG2\n",
    "from cv2.bgsegm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bg in bg_types:\n",
    "#     help(createBackgroundSubtractorCNT)\n",
    "    help(globals()['createBackgroundSubtractor'+bg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOG2\n",
      "KNN\n",
      "CNT\n",
      "GMG\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:715: error: (-215:Assertion failed) !_img.empty() in function 'imwrite'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.2.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:715: error: (-215:Assertion failed) !_img.empty() in function 'imwrite'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSOC\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSBP\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOG\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Ntraining = 50\n",
    "\n",
    "bg_types = ['MOG2','KNN','CNT','GMG','GSOC','LSBP','MOG']\n",
    "# bg_types = ['MOG2','GSOC','CNT']\n",
    "\n",
    "# bg_sub = cv2.createBackgroundSubtractorMOG2(history=Ntraining) #, varThreshold=25, detectShadows=False)\n",
    "# bg_sub = createBackgroundSubtractorKNN() #history=10*Ntraining)\n",
    "# bg_sub = createBackgroundSubtractorCNT()\n",
    "# bg_sub = createBackgroundSubtractorGMG()\n",
    "# bg_sub = createBackgroundSubtractorGSOC()\n",
    "# bg_sub = createBackgroundSubtractorLSBP()\n",
    "# bg_sub = createBackgroundSubtractorMOG()\n",
    "\n",
    "bgs_dir = join(output_dir,'backgrounds')\n",
    "if not os.path.exists(bgs_dir):\n",
    "    os.mkdir(bgs_dir)\n",
    "\n",
    "for bg in bg_types:\n",
    "    \n",
    "    print(bg)\n",
    "\n",
    "    cap = cv2.VideoCapture(new_input_file)\n",
    "    Nframes = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    training_frames = np.linspace(0, Nframes-1, Ntraining, dtype=int)\n",
    "    \n",
    "    try:\n",
    "        opt = dict(history=Ntraining) if bg in ['MOG2','KNN','MOG'] else {}\n",
    "        bg_sub = globals()['createBackgroundSubtractor'+bg](**opt)\n",
    "\n",
    "        for i in training_frames:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "            ret,frame = cap.read()\n",
    "    #         print(ret)\n",
    "            if ret:\n",
    "                bg_sub.apply(frame,learningRate=1/Ntraining)\n",
    "        #         cv2.imwrite(f'test/MOG/{i}.png',bg_sub.getBackgroundImage())\n",
    "\n",
    "        cap.release()\n",
    "#         cv2.imwrite(f'test/MOG/{bg}-{Ntraining}.png',bg_sub.getBackgroundImage())\n",
    "        cv2.imwrite(join(bgs_dir,f'{bg}-{Ntraining}.png'),bg_sub.getBackgroundImage())\n",
    "    except:\n",
    "        cap.release()\n",
    "        %tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cvtracer)",
   "language": "python",
   "name": "cvtracer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
