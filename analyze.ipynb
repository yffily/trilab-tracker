{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import platform, os, sys, datetime, re, itertools, warnings, pickle, bz2\n",
    "from os.path import join\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tracker.utils as utils\n",
    "from collections import defaultdict\n",
    "\n",
    "tank_diameter_vs_age = { 7:9.6, 14:10.4, 21:12.8, 28:17.7, 42:33.8,\n",
    "                         56:33.8, 70:33.8, 84:3.8 }\n",
    "tank_radius_vs_age = { k:v/2 for k,v in tank_diameter_vs_age.items() }\n",
    "# plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['figure.figsize'] = 9,6\n",
    "\n",
    "analysis_dir = './analysis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare trial data.\n",
    "\n",
    "Prepare a dictionary of trials to analyze with basic info for each (path to trial file, population, age, number of individuals, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to load a trial's tracking output.\n",
    "def load_trial(trial_file,load_data=True):\n",
    "    trial_dir  = os.path.dirname(trial_file)\n",
    "    trial_name = os.path.basename(trial_dir)\n",
    "    pop,day,age,group,n_ind = trial_name.split('_')[:5]\n",
    "    pop        = {'sf':'SF', 'pa':'Pa', 'rc':'RC'}[pop.lower()]\n",
    "    age        = int(age[:-3])\n",
    "    age = 42 if age==43 else (70 if age==71 else age)\n",
    "    n_ind      = int(re.findall('\\d+',n_ind)[0])\n",
    "    trial      = { k:v for k,v in locals().items() if k in ['trial_dir', \n",
    "                   'trial_name', 'pop', 'age', 'group', 'n_ind'] }\n",
    "    trial['R_cm'] = tank_radius_vs_age.get(age,None)\n",
    "    if load_data:\n",
    "        with open(trial_file,'rb') as f:\n",
    "            trial.update(pickle.load(f))\n",
    "        ellipse = cv2.fitEllipse(trial['tank']['contour'])\n",
    "        trial['center'] = np.array(ellipse[0])\n",
    "        trial['R_px']   = np.mean(ellipse[1])/2\n",
    "    return trial\n",
    "\n",
    "# Select a set of trials to analyze.\n",
    "trial_files = sorted(glob('../tracking/full_21-01-22/*/trial.pik'))\n",
    "\n",
    "# Count trials of each type.\n",
    "trials = [load_trial(f,load_data=False) for f in trial_files]\n",
    "trials = pd.DataFrame(trials,index=trial_files)\n",
    "grouped_trials = trials.groupby(['pop','age','n_ind'])\n",
    "count  = pd.DataFrame(grouped_trials['trial_dir'].count().rename('count'))\n",
    "count = count.unstack(1)\n",
    "count.columns = count.columns.droplevel()\n",
    "count[pd.isna(count)] = 0\n",
    "count = count.astype(int)\n",
    "print('Number of trials of each type:')\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define analysis functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dist2ellipse(semi_major, semi_minor, xy):\n",
    "#     px,py = np.absolute(xy)\n",
    "#     tx,ty = 0.707,0.707\n",
    "#     a = semi_major\n",
    "#     b = semi_minor\n",
    "#     for x in range(0, 3):\n",
    "#         x   = a * tx\n",
    "#         y   = b * ty\n",
    "#         ex  = (a*a - b*b) * tx**3 / a\n",
    "#         ey  = (b*b - a*a) * ty**3 / b\n",
    "#         rx  = x - ex\n",
    "#         ry  = y - ey\n",
    "#         qx  = px - ex\n",
    "#         qy  = py - ey\n",
    "#         r   = np.hypot(ry, rx)\n",
    "#         q   = np.hypot(qy, qx)\n",
    "#         tx  = min(1, max(0, (qx * r / q + ex) / a))\n",
    "#         ty  = min(1, max(0, (qy * r / q + ey) / b))\n",
    "#         t   = np.hypot(ty, tx)\n",
    "#         tx /= t \n",
    "#         ty /= t \n",
    "#     return (np.copysign(a * tx, xy[0]), np.copysign(b * ty, xy[1]))    \n",
    "\n",
    "\n",
    "def compute_kinematics(trial,wall_distance=False):\n",
    "    center      = trial['center']\n",
    "    px2cm       = trial['R_cm']/trial['R_px']\n",
    "    n           = trial['n_ind']\n",
    "    pos         = trial['data'][:,:n,:3].copy() # discard extra objects\n",
    "    pos[:,:,:2] = (pos[:,:,:2]-center[None,None,:])*px2cm # convert to centimeters\n",
    "    pos[:,:,1]  = -pos[:,:,1] # flip y axis\n",
    "    for j in range(n): # unwrap orientations\n",
    "        I          = ~np.isnan(pos[:,j,2])\n",
    "        pos[I,j,2] = np.unwrap(pos[I,j,2])\n",
    "    time        = trial['frame_list']/trial['fps']\n",
    "    vel         = np.gradient(pos,time,axis=0)\n",
    "    acc         = np.gradient(vel,time,axis=0)\n",
    "    v           = np.hypot(vel[:,:,0],vel[:,:,1])\n",
    "    \n",
    "    d_wall      = trial['R_cm'] - np.hypot(pos[:,:,0],pos[:,:,1])\n",
    "# #     dist    = lambda xy: dist2ellipse(*ellipse[1],xy)\n",
    "#     dist    = lambda xy: cv2.pointPolygonTest(trial['tank']['contour'],tuple(xy),True)\n",
    "#     d_wall  = px2cm * np.apply_along_axis(dist,2,trial['data'][:,:,:2])\n",
    "    \n",
    "    trial.update({ k:v for k,v in locals().items() if k in \n",
    "                   ['time', 'pos', 'vel', 'acc', 'd_wall', 'v'] })\n",
    "    return trial\n",
    "\n",
    "\n",
    "def compute_cuts(trial,ranges):\n",
    "    # Distances in ut ranges\n",
    "    globals().update(trial)\n",
    "    \n",
    "    # valid array: axis 0 = time, axis 1 = [nan_xy,nan_any,d_wall,v,v_ang,final]\n",
    "    valid  = np.full(pos.shape[:2]+(7,),np.True_,dtype=np.bool_)\n",
    "    valid[:,:,0] = np.logical_not(np.any(np.isnan(pos),axis=2))\n",
    "    valid[:,:,1] = np.logical_not(np.any(np.isnan(vel),axis=2))\n",
    "    valid[:,:,2] = np.logical_not(np.any(np.isnan(acc),axis=2))\n",
    "    valid[:,:,3] = np.logical_and(d_wall>=ranges['d_wall'][0],d_wall<=ranges['d_wall'][1])\n",
    "    valid[:,:,4] = np.logical_and(v>=ranges['v'][0],v<=ranges['v'][1])\n",
    "    valid[:,:,5] = np.logical_and(vel[:,:,2]>=ranges['v_ang'][0],vel[:,:,2]<=ranges['v_ang'][1])\n",
    "    valid[:,:,6] = np.all(valid[:,:,:5],axis=2)\n",
    "    \n",
    "    n_total = valid.shape[0]*valid.shape[1]\n",
    "    n_valid = np.count_nonzero(valid,axis=(0,1))\n",
    "    valid_fraction = { 'nan_pos' : n_valid[0]/n_total, \n",
    "                       'nan_vel' : n_valid[1]/n_total, \n",
    "                       'nan_acc' : n_valid[2]/n_total, \n",
    "                       'd_wall'  : n_valid[3]/n_valid[0], \n",
    "                       'v'       : n_valid[4]/n_valid[1], \n",
    "                       'v_ang'   : n_valid[5]/n_valid[1], \n",
    "                       'final'   : n_valid[6]/n_total     }\n",
    "    \n",
    "    trial.update({'valid':valid, 'valid_fraction':valid_fraction, 'cut_label':cut_label})\n",
    "    return trial\n",
    "\n",
    "\n",
    "# t0 = datetime.datetime.now()\n",
    "# trial = load_trial(trial_files[0], load_data=True)\n",
    "# trial = compute_kinematics(trial)\n",
    "# trial = compute_cuts(trial)\n",
    "# print(datetime.datetime.now()-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [in progress] Detect discrete turns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,trial_file in enumerate(trials.index):\n",
    "#     print('\\r'+' '*200+'\\r'+f'{i}/{len(trial_files)}',end='')\n",
    "#     trial = load_trial(trial_file, load_data=True)\n",
    "#     trial = compute_kinematics(trial)\n",
    "#     locals().update(trial)\n",
    "#     # Plot angle.\n",
    "#     a = pos[:,0,2]\n",
    "#     plt.plot(time,a,label='actual angle')\n",
    "#     # Extract discrete turns.\n",
    "#     w = int(0.15*fps)\n",
    "#     step = np.concatenate([np.ones(w)/w,np.zeros(1),-np.ones(w)/w])\n",
    "#     conv = np.convolve(a,step,mode='same')\n",
    "#     P = find_peaks(np.absolute(conv),distance=w,height=np.pi/20)\n",
    "#     # Reconstruct angle vs time using only the discrete turns.\n",
    "#     da = np.zeros_like(a)\n",
    "#     da[P[0]] = conv[P[0]]\n",
    "#     a2 = a[0]+np.cumsum(da)\n",
    "#     plt.plot(time,a2,label='reconstructed angle')\n",
    "    \n",
    "#     plt.plot(time,a-a2,label='actual angle - reconstructed angle')\n",
    "    \n",
    "# #     plt.xlim(0,1000)\n",
    "# #     plt.ylim(2,15)\n",
    "#     plt.legend()\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(1,2,figsize=(12,4))\n",
    "# I = P[0]\n",
    "# dt = time[I[1:]]-time[I[:-1]]\n",
    "# ax[0].hist(dt,bins=50)\n",
    "# ax[0].set_xlabel('time between two discrete turns')\n",
    "# ax[0].set_ylabel('frequency')\n",
    "# ax[0].set_yscale('log')\n",
    "# ax[1].hist(np.absolute(conv[I]),bins=50)\n",
    "# ax[1].set_xlabel('angle turned')\n",
    "# ax[1].set_yscale('log')\n",
    "# plt.suptitle('Discrete turns')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# fig,ax = plt.subplots(1,2,figsize=(12,4))\n",
    "# da = np.diff(a-a2)/np.sqrt(time[1:]-time[:-1])\n",
    "# ax[0].hist(da,bins=100)\n",
    "# ax[0].set_xlabel('da/sqrt(dt)')\n",
    "# ax[0].set_ylabel('frequency')\n",
    "# # dt = time[I[1:]]-time[I[:-1]]\n",
    "# # ax[0].hist(dt,bins=20)\n",
    "# # ax[1].hist(np.absolute(conv[I]),bins=50)\n",
    "# # plt.xlim(-5,5)\n",
    "# ax[0].set_yscale('log')\n",
    "# ax[1].set_visible(False)\n",
    "# plt.suptitle('Continuous turns')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute or load analyzed data.\n",
    "\n",
    "The first subsection iterates over the list of trials, loads the full tracking output, compute kinematic quantities, performs cuts, computes statistical properties (distribution of speed, angular speed, pairwise distance-angle, etc), and saves them.\n",
    "\n",
    "The second subsection loads precomputed statistical properties made with the first cell.\n",
    "\n",
    "### Define cuts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed cut: 0.2*30 = travel 0.2 tank radius between 2 frames at 30fps.\n",
    "# Angular speed cut: pi/2*30 = quarter turn between 2 frames at 30 fps.\n",
    "cut_ranges    = { 'd_wall':[-np.inf,np.inf], 'v':[0,0.2*30], \n",
    "                  'v_ang':[-np.pi/2*30,np.pi/2*30] }\n",
    "# This is used to name the output directory and make figure titles.\n",
    "# The \"=\" should be \"<=\" however ntfs doesn't allow \"<\" in filenames.\n",
    "cut_label     = ', '.join([ f'{v[0]:g}={k}={v[1]:g}' for k,v in cut_ranges.items() ])\n",
    "\n",
    "cut_dir = os.path.join(analysis_dir,cut_label)\n",
    "if not os.path.exists(cut_dir):\n",
    "    os.mkdir(cut_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_area     = np.linspace(0,600,100)\n",
    "bins_aspect   = np.linspace(1,15,100)\n",
    "prebins_dWall = np.linspace(-0.1,1.1,100) # Multiply by R_cm before using.\n",
    "prebins_v     = np.linspace(*cut_ranges['v'],100) # Multiply by R_cm before using.\n",
    "bins_vAng     = np.linspace(*cut_ranges['v_ang'],100)\n",
    "prebins_pairDist = np.linspace(0,2,60) # Multiply by R_cm before using.\n",
    "bins_pairAng  = np.linspace(0,np.pi,30)\n",
    "\n",
    "trial_data    = {}\n",
    "\n",
    "for i,trial_file in enumerate(trials.index):\n",
    "    print('\\r'+' '*200+'\\r'+f'{i+1}/{len(trials)}',end='')\n",
    "    \n",
    "    trial  = load_trial(trial_file, load_data=True)\n",
    "    ranges = { 'd_wall': [ x*trial['R_cm'] for x in cut_ranges['d_wall'] ], \n",
    "               'v':      [ x*trial['R_cm'] for x in cut_ranges['v'] ], \n",
    "               'v_ang':  cut_ranges['v_ang'] }\n",
    "    trial  = compute_kinematics(trial)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        trial = compute_cuts(trial, ranges)\n",
    "    globals().update(trial)\n",
    "    \n",
    "    # Fish area and Fish aspect ratio histograms.\n",
    "    # Useful to tune the tracker's contour filters.\n",
    "    hist_area   = np.histogram(data[:,:n_ind,3], bins=bins_area )\n",
    "    hist_aspect = np.histogram(data[:,:n_ind,4], bins=bins_aspect )\n",
    "    \n",
    "    # Distribution of distance to the wall.\n",
    "    bins = prebins_dWall * R_cm\n",
    "    vals = d_wall.flatten()\n",
    "    hist_dWall = np.histogram(vals[~np.isnan(vals)],bins=bins)\n",
    "    \n",
    "    # Speed distribution.\n",
    "    bins = prebins_v * R_cm\n",
    "    vals = v.flatten()\n",
    "    hist_v = np.histogram(vals[~np.isnan(vals)],bins=bins)\n",
    "    \n",
    "    # Angular speed distribution.\n",
    "    bins = bins_vAng\n",
    "    vals = vel[:,:,2].flatten()\n",
    "    hist_vAng = np.histogram(vals[~np.isnan(vals)],bins=bins)\n",
    "    \n",
    "    # Joint distribution of pair distance and pair angle,\n",
    "    if n_ind>1:\n",
    "        bins_d  = prebins_pairDist * R_cm\n",
    "        bins_a  = bins_pairAng\n",
    "        J1,J2 = np.triu_indices(n_ind,1)\n",
    "        d     = np.hypot(pos[:,J1,0]-pos[:,J2,0],pos[:,J1,1]-pos[:,J2,1]).flatten()\n",
    "        a     = (pos[:,J1,2]-pos[:,J2,2]).flatten()\n",
    "        a     = a - 2*np.pi*np.rint(a/(2*np.pi))\n",
    "        I     = np.logical_not(np.logical_or(np.isnan(d),np.isnan(a)))\n",
    "        d     = d[I]\n",
    "        a     = np.absolute(a[I])\n",
    "        # 2D histogram of pairwise distance and angle.\n",
    "        hist_distAng = np.histogram2d(d, a, bins=(bins_d,bins_a), density=True)\n",
    "        # Pairwise polar alignment parameter vs pair distance.\n",
    "        K = np.digitize(d,bins_d)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            p = np.array([ np.nanmean(np.cos(a[K==i])) for i in range(len(bins_d)+1) ])\n",
    "        polar = p[1:-1],bins_d\n",
    "    else:\n",
    "        hist_distAng,polar = None,None\n",
    "\n",
    "    # Save output.\n",
    "    trial_data[trial_file] = { k:v for k,v in locals().items() if k in \n",
    "                               [ 'valid_fraction', 'hist_area', 'hist_aspect', 'hist_dWall', \n",
    "                                 'hist_v', 'hist_vAng', 'hist_distAng', 'polar' ] }\n",
    "#     break\n",
    "\n",
    "\n",
    "f = os.path.join(cut_dir,'trial_data')\n",
    "# pickle.dump( {'trial_data':trial_data}, bz2.BZ2File(f+'.bz2','w') )\n",
    "pickle.dump( {'trial_data':trial_data}, open(f+'.pik','wb') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load precomputed analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List previously computed cuts.\n",
    "cut_dirs = os.listdir(analysis_dir)\n",
    "print(cut_dirs)\n",
    "cut_label = cut_dirs[0]\n",
    "\n",
    "f    = os.path.join(analysis_dir,cut_label,'trial_data')\n",
    "data = pickle.load( open(f+'.pik','rb') )\n",
    "globals().update(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot\n",
    "\n",
    "Distributions and other statistical quantities were precomputed in the previous section. Time series and trajectories plots require to reload each trial's trial file, one at a time.\n",
    "\n",
    "### Trajectories and time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_dir = { k:os.path.join(analysis_dir,cut_label,k) for k in \n",
    "#                ['trajectories', 'angle-vs-time'] }\n",
    "# for d in fig_dir.values():\n",
    "#     if not os.path.exists(d):\n",
    "#         os.mkdir(d)\n",
    "\n",
    "# # Creating a new figure for each trial creates a memory leak\n",
    "# # I haven't been able to plug, so I'm creating one figure for\n",
    "# # trajectories and one for angles and reusing them.\n",
    "# fig_traj = plt.figure(figsize=(9,)*2)\n",
    "# fig_ang  = plt.figure(figsize=(12,6))\n",
    "\n",
    "# for i,trial_file in enumerate(trials.index):\n",
    "#     print('\\r'+' '*200+'\\r'+f'{i+1}/{len(trials)}',end='')\n",
    "    \n",
    "#     trial = load_trial(trial_file, load_data=True)\n",
    "#     trial = compute_kinematics(trial)\n",
    "#     globals().update(trial)\n",
    "    \n",
    "#     # Trajectories.\n",
    "#     fig,ax = fig_traj,fig_traj.gca()\n",
    "#     ax.add_patch(plt.Circle(center, R_px, facecolor='None', \n",
    "#                                    edgecolor='k', lw=0.5))\n",
    "#     ax.plot(*np.moveaxis(data[::5,:n_ind,:2],2,0),lw=0.5)\n",
    "#     ax.axis('equal')\n",
    "#     ax.yaxis.set_inverted(True)\n",
    "#     fig.suptitle(trial_name)\n",
    "#     fig.savefig(os.path.join(fig_dir['trajectories'],trial_name+'.png'))\n",
    "#     fig.clf()\n",
    "    \n",
    "#     # Angle vs time.\n",
    "#     fig,ax = fig_traj,fig_traj.gca()\n",
    "#     ax.plot(time[:,None],pos[:,:,2])\n",
    "#     ax.set_xlabel('Time (s)')\n",
    "#     ax.set_ylabel('Angle (rad)')\n",
    "#     fig.suptitle(trial_name)\n",
    "#     fig.savefig(os.path.join(fig_dir['angle-vs-time'],trial_name+'.png'))\n",
    "#     fig.clf()\n",
    "    \n",
    "# plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f    = os.path.join(analysis_dir,cut_label,'trial_data')\n",
    "# data = pickle.load( open(f+'.pik','rb') )\n",
    "# globals().update(data)\n",
    "\n",
    "# fig_dir = { k:os.path.join(analysis_dir,cut_label,k) for k in [ #'valid_fraction', \n",
    "#             'hist_dWall', 'hist_v', 'hist_vAng', 'hist_distAng', 'polar' ] }\n",
    "# for d in fig_dir.values():\n",
    "#     if not os.path.exists(d):\n",
    "#         os.mkdir(d)\n",
    "\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax  = fig.gca()\n",
    "\n",
    "# for i,trial_file in enumerate(trials.index):\n",
    "#     print('\\r'+' '*200+'\\r'+f'{i+1}/{len(trials)}',end='')\n",
    "    \n",
    "#     globals().update(trials.loc[trial_file].to_dict())\n",
    "#     globals().update(trial_data[trial_file])\n",
    "    \n",
    "# #     # Valid fraction.\n",
    "# #     bp = plt.bar(*zip(*valid_fraction.items()))\n",
    "# #     for bar in bp:\n",
    "# #         h,x,w = bar.get_height(),bar.get_x(),bar.get_width()\n",
    "# #         plt.annotate(f'{h:.2f}', xy=(x+w/2,1.01), ha='center', va='bottom')\n",
    "# #     plt.ylim(0,1.1)\n",
    "# #     plt.ylabel('Valid fraction')\n",
    "# #     plt.title(cut_label)\n",
    "# #     plt.suptitle(trial_name)\n",
    "# #     plt.savefig(os.path.join(fig_dir['valid_fraction'],trial_name+'.png'))\n",
    "# #     plt.close()\n",
    "    \n",
    "#     # Distributions of distance to the wall, speed, and angular speed.\n",
    "#     H = dict( hist_dWall='d_wall (cm)', hist_v='v (cm/s)', hist_vAng='v_ang (rad/s)' )\n",
    "#     for name,label in H.items():\n",
    "#         ax = fig.gca()\n",
    "#         h,b = locals()[name]\n",
    "#         ax.bar(b[:-1],h,width=b[1:]-b[:-1])\n",
    "#         ax.set_yscale('log')\n",
    "#         ax.set_xlabel(label)\n",
    "#         ax.set_ylabel('frequency')\n",
    "#         ax.set_title(cut_label)\n",
    "#         fig.suptitle(trial_name)\n",
    "#         fig.savefig(os.path.join(fig_dir[name],trial_name+'.png'))\n",
    "#         fig.clf()\n",
    "    \n",
    "#     # Pairwise distance-angle distribution.\n",
    "#     if not hist_distAng is None:\n",
    "#         ax = fig.gca()\n",
    "#         h,b1,b2 = hist_distAng\n",
    "#         m = ax.pcolormesh(b1, b2*180/np.pi, h.T, cmap='Oranges')\n",
    "#         ax.set_xlabel('pair distance (cm)')\n",
    "#         ax.set_ylabel('pair angle (deg)')\n",
    "#         fig.colorbar(m)\n",
    "#         ax.set_title(cut_label)\n",
    "#         fig.suptitle(trial_name)\n",
    "#         fig.savefig(os.path.join(fig_dir['hist_distAng'],trial_name+'.png'))\n",
    "#         fig.clf()\n",
    "    \n",
    "#     # Pairwise polar order parameter vs distance.\n",
    "#     if not polar is None:\n",
    "#         ax = fig.gca()\n",
    "#         p,b = polar\n",
    "#         ax.plot((b[1:]+b[:-1])/2,p,marker='o',mfc='None',ms=4)\n",
    "#         ax.set_xlabel('pair distance (cm)')\n",
    "#         ax.set_ylabel('mean cosine of pair angle')\n",
    "#         ax.set_ylim(-1,1)\n",
    "#         ax.set_title(cut_label)\n",
    "#         fig.suptitle(trial_name)\n",
    "#         fig.savefig(os.path.join(fig_dir['polar'],trial_name+'.png'))\n",
    "#         fig.clf()\n",
    "    \n",
    "# #     if i==10:\n",
    "# #         break\n",
    "\n",
    "# plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' Analyze instances of unusually high velocity. '''\n",
    "\n",
    "# # At 30 fps, |v_ang|=30 (about where the rare peaks start) \n",
    "# # corresponds to about pi/3 in one frame.\n",
    "# print('v_ang for pi/3 in (1/30) second:',np.pi/3*fps)\n",
    "\n",
    "# print('Instances of unusually high v_ang:')\n",
    "# for f in fish_list:\n",
    "#     ang_diff  = df[f,'ang'].diff()\n",
    "#     I = np.nonzero(np.absolute(ang_diff.values)>1)[0]\n",
    "#     for i in I[:5]:\n",
    "#         display(df[f,'ang'].iloc[i-1:i+2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area and aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f    = os.path.join(analysis_dir,cut_label,'trial_data')\n",
    "data = pickle.load( open(f+'.pik','rb') )\n",
    "globals().update(data)\n",
    "\n",
    "for pop,files1 in trials.groupby('pop').groups.items():\n",
    "    fig,ax = plt.subplots(1,2,figsize=(12,3))\n",
    "    fig.suptitle(pop)\n",
    "    for age,files2 in trials.loc[files1].groupby('age').groups.items():\n",
    "        for i,name in enumerate(['hist_area','hist_aspect']):\n",
    "            b = trial_data[files2[0]][name][1]\n",
    "            h = np.mean([trial_data[f][name][0] for f in files2],axis=0)\n",
    "            ax[i].plot(b[:-1],h,label=f'{age}')\n",
    "        \n",
    "    for i in range(2):\n",
    "        ax[i].set_title(['Fish Area','Fish Aspect Ratio'][i])\n",
    "        ax[i].legend(title='age')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f    = os.path.join(analysis_dir,cut_label,'trial_data')\n",
    "data = pickle.load( open(f+'.pik','rb') )\n",
    "globals().update(data)\n",
    "\n",
    "grouped_valid_fractions = {}\n",
    "for g,files in grouped_trials.groups.items():\n",
    "    grouped_valid_fractions[g] = defaultdict(list)\n",
    "    for i,f in enumerate(files):\n",
    "        for cut,vf in trial_data[f]['valid_fraction'].items():\n",
    "            grouped_valid_fractions[g][cut].append(vf)\n",
    "\n",
    "''' Boxplot of the fraction of valid frames for each type of invalidity. \n",
    "    One boxplot for each type of trial. '''\n",
    "# for k,valid_fractions in grouped_valid_fractions.items():\n",
    "#     plt.boxplot(valid_fractions.values(),labels=valid_fractions.keys())\n",
    "# #     plt.violinplot([valid_fractions[c] for c in cut_names],showextrema=False)\n",
    "#     plt.xlabel('Cut')\n",
    "#     plt.ylabel('Valid fraction')\n",
    "#     plt.ylim(0,1.05)\n",
    "#     pop,age,n_ind = k\n",
    "#     name = f'{pop}_{age}dpf_n{n_ind}'\n",
    "#     plt.title(name)\n",
    "#     plt.show()\n",
    "\n",
    "''' Boxplot of the fraction of valid frames for each type of trial. \n",
    "    One boxplot for each type of invalidity. '''\n",
    "# for cut_type in next(iter(grouped_valid_fractions.values())).keys():\n",
    "#     vf_summary = { f'{k[0]}_{k[1]}dpf_n{k[2]}':vf[cut_type] for k,vf in grouped_valid_fractions.items() }\n",
    "#     plt.figure(figsize=(12,4))\n",
    "#     plt.boxplot(vf_summary.values(),labels=vf_summary.keys())\n",
    "#     plt.ylabel('Valid fraction')\n",
    "#     plt.ylim(0,1)\n",
    "#     plt.xticks(rotation=90)\n",
    "#     plt.title(cut_type)\n",
    "#     plt.show()\n",
    "\n",
    "''' Boxplot of the fraction of valid frames for each type of trial. '''\n",
    "cut_types = next(iter(grouped_valid_fractions.values())).keys()\n",
    "# for cut_type in cut_types:\n",
    "for cut_type in ['final']:\n",
    "    vf_summary = { f'{k[0]}_{k[1]}dpf_n{k[2]}':vf[cut_type] for k,vf in grouped_valid_fractions.items() }\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.boxplot(vf_summary.values(),labels=vf_summary.keys())\n",
    "    plt.ylabel('Valid fraction')\n",
    "    plt.ylim(0,1.02)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(f'{cut_type} cut')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Identify trials with a higher fraction of invalid frames. '''\n",
    "\n",
    "for f in trials.index:\n",
    "    vf = trial_data[f]['valid_fraction']\n",
    "    if vf['final']<0.8:\n",
    "        print(trials.loc[f]['trial_name'])\n",
    "        print(', '.join([ f'{k}:{v:.2g}' for k,v in vf.items() ]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wall distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f    = os.path.join(analysis_dir,cut_label,'trial_data')\n",
    "data = pickle.load( open(f+'.pik','rb') )\n",
    "globals().update(data)\n",
    "\n",
    "pops = trials['pop'].unique()\n",
    "ages = np.sort(trials['age'].unique())\n",
    "colors = dict(zip( ages, plt.cm.viridis(np.linspace(0,1,len(ages))) ))\n",
    "\n",
    "for pop in pops:\n",
    "    fig,axs = plt.subplots(1,2,figsize=(12,4))\n",
    "    for age in ages:\n",
    "        for i,n_ind in enumerate([2,5]):\n",
    "            ax = axs[i]\n",
    "            files = grouped_trials.get_group((pop,age,n_ind)).index\n",
    "            h,b = trial_data[files[0]]['hist_dWall']\n",
    "            b   = b/tank_radius_vs_age[age]\n",
    "            x   = (b[1:]+b[:-1])/2\n",
    "            H = np.array([ trial_data[f]['hist_dWall'][0] for f in files ])\n",
    "            h = np.nansum(H,axis=0)\n",
    "            h   = h/(2*np.pi*(1-x))\n",
    "            m = ax.plot(x, h, color=colors[age], label=f'{age}dpf')\n",
    "    for i,n_ind in enumerate([2,5]):\n",
    "        ax = axs[i]\n",
    "#         ax.set_ylim(1e1,None)\n",
    "        ax.set_xlabel('distance to the wall (tank radii)')\n",
    "        ax.set_ylabel('density per unit area (arbitrary units)')\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_title(f'{pop}_n{n_ind}')\n",
    "        ax.legend(ncol=2)\n",
    "    plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f    = os.path.join(analysis_dir,cut_label,'trial_data')\n",
    "data = pickle.load( open(f+'.pik','rb') )\n",
    "globals().update(data)\n",
    "\n",
    "pops = trials['pop'].unique()\n",
    "ages = np.sort(trials['age'].unique())\n",
    "colors = dict(zip( ages, plt.cm.viridis(np.linspace(0,1,len(ages))) ))\n",
    "\n",
    "for pop in pops:\n",
    "    fig,axs = plt.subplots(1,2,figsize=(12,4))\n",
    "    for age in ages:\n",
    "        for i,n_ind in enumerate([2,5]):\n",
    "            ax = axs[i]\n",
    "            files = grouped_trials.get_group((pop,age,n_ind)).index\n",
    "            h,b = trial_data[files[0]]['hist_v']\n",
    "            b   = b/tank_radius_vs_age[age]\n",
    "            H = np.array([ trial_data[f]['hist_v'][0] for f in files ])\n",
    "            h = np.nansum(H,axis=0)\n",
    "            m = ax.plot((b[1:]+b[:-1])/2, h, color=colors[age], label=f'{age}dpf')\n",
    "    for i,n_ind in enumerate([2,5]):\n",
    "        ax = axs[i]\n",
    "        ax.set_xlim(0,3)\n",
    "        ax.set_xlabel('speed (tank radii/s)')\n",
    "        ax.set_ylabel('frequency')\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_title(f'{pop}_n{n_ind}')\n",
    "        ax.legend()\n",
    "    plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angular speed distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f    = os.path.join(analysis_dir,cut_label,'trial_data')\n",
    "data = pickle.load( open(f+'.pik','rb') )\n",
    "globals().update(data)\n",
    "\n",
    "pops = trials['pop'].unique()\n",
    "ages = np.sort(trials['age'].unique())\n",
    "colors = dict(zip( ages, plt.cm.viridis(np.linspace(0,1,len(ages))) ))\n",
    "\n",
    "for pop in pops:\n",
    "    fig,axs = plt.subplots(1,2,figsize=(12,4))\n",
    "    for age in ages:\n",
    "        for i,n_ind in enumerate([2,5]):\n",
    "            ax = axs[i]\n",
    "            files = grouped_trials.get_group((pop,age,n_ind)).index\n",
    "            h,b = trial_data[files[0]]['hist_vAng']\n",
    "            H = np.array([ trial_data[f]['hist_vAng'][0] for f in files ])\n",
    "            h = np.nansum(H,axis=0)\n",
    "            m = ax.plot((b[1:]+b[:-1])/2, h, color=colors[age], label=f'{age}dpf')\n",
    "    for i,n_ind in enumerate([2,5]):\n",
    "        ax = axs[i]\n",
    "        ax.set_xlabel('speed (rad/s)')\n",
    "        ax.set_ylabel('frequency')\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_title(f'{pop}_n{n_ind}')\n",
    "        ax.legend()\n",
    "    plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint pair distance-pair angle distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for (pop,age,n_ind),files in grouped_trials.groups.items():\n",
    "#     if n_ind==1:\n",
    "#         continue\n",
    "#     h,b1,b2 = trial_data[files[0]]['hist_distAng']\n",
    "#     H = np.array([ trial_data[f]['hist_distAng'][0] for f in files ])\n",
    "#     h = np.nanmean(H,axis=0)\n",
    "#     plt.pcolormesh(bins_d, bins_a*180/np.pi, h.T, cmap='Oranges')\n",
    "#     plt.xlabel('pair distance (cm)')\n",
    "#     plt.ylabel('pair angle (deg)')\n",
    "#     plt.colorbar()\n",
    "#     plt.title(cut_label)\n",
    "#     plt.suptitle(f'{pop}_{age}dpf_n{n_ind}')\n",
    "#     plt.show()\n",
    "# #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pops = trials['pop'].unique()\n",
    "ages = np.sort(trials['age'].unique())\n",
    "\n",
    "# for pop in pops:\n",
    "for pop in ['RC']:\n",
    "    for age in ages:\n",
    "        fig,axs = plt.subplots(1,2,figsize=(12,4))\n",
    "        for i,n_ind in enumerate([2,5]):\n",
    "            ax = axs[i]\n",
    "            files = grouped_trials.get_group((pop,age,n_ind)).index\n",
    "            h,b1,b2 = trial_data[files[0]]['hist_distAng']\n",
    "            H = np.array([ trial_data[f]['hist_distAng'][0] for f in files ])\n",
    "            h = np.nanmean(H,axis=0)\n",
    "            m = ax.pcolormesh(b1, b2*180/np.pi, h.T, cmap='Oranges')\n",
    "            ax.set_xlabel('pair distance (cm)')\n",
    "            ax.set_ylabel('pair angle (deg)')\n",
    "            fig.colorbar(m,ax=ax)\n",
    "            ax.set_title(f'{pop}_{age}dpf_n{n_ind}')\n",
    "        plt.show()\n",
    "#         break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pops   = trials['pop'].unique()\n",
    "ages   = np.sort(trials['age'].unique())\n",
    "colors = dict(zip( ages, plt.cm.viridis(np.linspace(0,1,len(ages))) ))\n",
    "\n",
    "n_ind  = 5\n",
    "for pop in pops:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    for age in ages:\n",
    "#         for i,n_ind in enumerate([2,5]):\n",
    "        files = grouped_trials.get_group((pop,age,n_ind)).index\n",
    "        p,b = trial_data[files[0]]['polar']\n",
    "        P = np.array([ trial_data[f]['polar'][0] for f in files ])\n",
    "        with warnings.catch_warnings():\n",
    "            p = np.mean(P,axis=0)\n",
    "        plt.plot( (b[1:]+b[:-1])/2/tank_radius_vs_age[age], p, lw=2, \n",
    "                  color=colors[age], label=f'{pop}_{age}dpf_n{n_ind}' )\n",
    "        plt.xlabel('pair distance/tank radius')\n",
    "        plt.ylabel('mean cosine of pair angle')\n",
    "        plt.ylim(-1,1)\n",
    "        plt.title(cut_label)\n",
    "    #     plt.suptitle(f'{pop}_{age}dpf_n{n_ind}')\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1.01,0.5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (main)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
